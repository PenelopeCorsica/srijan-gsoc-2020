{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Federated Learning - GTEx_V8 Example</h1>\n",
    "<h2>Populate remote PyGrid nodes with labeled tensors </h2>\n",
    "In this notebook, we will populate our PyGrid nodes with labeled data so that it will be used later by people interested in train models.\n",
    "\n",
    "**NOTE:** At the time of running this notebook, we were running the grid components in background mode.  \n",
    "\n",
    "Components:\n",
    " - PyGrid Network (http://localhost:5000)\n",
    " - PyGrid Node h1 (http://localhost:3000)\n",
    " - PyGrid Node h2 (http://localhost:3001)\n",
    " \n",
    "Code implementation for this notebook has been referred from <a href=\"https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb\">Fed.Learning MNIST [ Part-1 ] - Populate a Grid Network ( Dataset )</a> tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "# Dynamic FL -->\n",
    "from syft.grid.clients.dynamic_fl_client import DynamicFLClient\n",
    "\n",
    "#Static FL -->\n",
    "from syft.grid.clients.static_fl_client import StaticFLClient\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setup config</h2>\n",
    "Init hook, connect with grid nodes, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Connect directly to grid nodes\n",
    "nodes = [\"ws://localhost:3000/\",\n",
    "         \"ws://localhost:3001/\"]\n",
    "\n",
    "compute_nodes = []\n",
    "for node in nodes:\n",
    "    compute_nodes.append( DynamicFLClient(hook, node) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Federated Worker id:h1>, <Federated Worker id:h2>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Dataset\n",
    "\n",
    "The code below will load GTEx data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajverma/Desktop/summerInternship2k17/GSoC/obf/generative_biolearn_project/GitHub/OpenMined/PySyft/syft/frameworks/torch/hook/hook.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/balanced/numpy_files/'\n",
    "shared_x1 = np.load(DATA_PATH + 'shared_x1.npy') # First chunk of dataset \n",
    "shared_x2 = np.load(DATA_PATH + 'shared_x2.npy') # Second chunk of dataset \n",
    "\n",
    "shared_y1 = np.load(DATA_PATH + 'shared_y1.npy') # First chunk of labels \n",
    "shared_y2 = np.load(DATA_PATH + 'shared_y2.npy') # Second chunk of labels \n",
    "\n",
    "# Convert numpy array to torch tensors -->\n",
    "shared_x1 = torch.from_numpy(shared_x1)\n",
    "shared_x2 = torch.from_numpy(shared_x2)\n",
    "shared_y1 = torch.from_numpy(shared_y1)\n",
    "shared_y2 = torch.from_numpy(shared_y2)\n",
    "\n",
    "shared_x1 = torch.tensor(shared_x1, dtype=torch.float32)\n",
    "shared_x2 = torch.tensor(shared_x2, dtype=torch.float32)\n",
    "shared_y1 = torch.tensor(shared_y1, dtype=torch.int64)\n",
    "shared_y2 = torch.tensor(shared_y2, dtype=torch.int64)\n",
    "\n",
    "datasets  = [shared_x1, shared_x2]\n",
    "labels = [shared_y1, shared_y2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below using centralized way (full data) --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training loss: 0.0014932347337404887  | Training Accuracy: 0.16666666666666666\n",
      "Epoch: 1 Training loss: 0.0014913400014241536  | Training Accuracy: 0.2325\n",
      "Epoch: 2 Training loss: 0.001492513914903005  | Training Accuracy: 0.16833333333333333\n",
      "Epoch: 3 Training loss: 0.001487403909365336  | Training Accuracy: 0.20666666666666667\n",
      "Epoch: 4 Training loss: 0.0014874201019605  | Training Accuracy: 0.22416666666666665\n",
      "Epoch: 5 Training loss: 0.0014906687537829082  | Training Accuracy: 0.23666666666666666\n",
      "Epoch: 6 Training loss: 0.0015001020828882853  | Training Accuracy: 0.205\n",
      "Epoch: 7 Training loss: 0.0014691548546155295  | Training Accuracy: 0.24916666666666668\n",
      "Epoch: 8 Training loss: 0.001472269892692566  | Training Accuracy: 0.21583333333333332\n",
      "Epoch: 9 Training loss: 0.0014627864956855774  | Training Accuracy: 0.25083333333333335\n",
      "Epoch: 10 Training loss: 0.0014587390422821046  | Training Accuracy: 0.2608333333333333\n",
      "Epoch: 11 Training loss: 0.0014493820071220399  | Training Accuracy: 0.28\n",
      "Epoch: 12 Training loss: 0.0014551818370819093  | Training Accuracy: 0.2725\n",
      "Epoch: 13 Training loss: 0.0014412696162859598  | Training Accuracy: 0.285\n",
      "Epoch: 14 Training loss: 0.0014410772919654846  | Training Accuracy: 0.2966666666666667\n",
      "Epoch: 15 Training loss: 0.0014316304524739584  | Training Accuracy: 0.31\n",
      "Epoch: 16 Training loss: 0.0014315265417098998  | Training Accuracy: 0.305\n",
      "Epoch: 17 Training loss: 0.0014241822560628254  | Training Accuracy: 0.31333333333333335\n",
      "Epoch: 18 Training loss: 0.0014175760746002197  | Training Accuracy: 0.335\n",
      "Epoch: 19 Training loss: 0.0014115408062934875  | Training Accuracy: 0.3466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Concatenate \n",
    "X = torch.cat((shared_x1, shared_x2), dim=0)\n",
    "Y = torch.cat((shared_y1, shared_y2), dim=0)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TODO: Define your network architecture here\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(18420, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Create the network, define the criterion and optimizer\n",
    "model = Classifier()\n",
    "# criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    \n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(X)\n",
    "    loss = F.cross_entropy(pred, Y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # statistics\n",
    "    #prob = F.softmax(pred, dim=1)\n",
    "    top1 = torch.argmax(pred, dim=1)\n",
    "    ncorrect = torch.sum(top1 == Y)\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_acc += ncorrect.item()\n",
    "\n",
    "    epoch_loss /= Y.shape[0]\n",
    "    epoch_acc /= Y.shape[0]\n",
    "\n",
    "    print(f\"Epoch: {e}\",f\"Training loss: {epoch_loss}\", f\" | Training Accuracy: {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 - Tagging tensors</h2>\n",
    "The code below will add a tag (of your choice) to the data that will be sent to grid nodes. This tag is important as the network will need it to retrieve this data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_input = []\n",
    "tag_label = []\n",
    "\n",
    "\n",
    "for i in range(len(compute_nodes)):\n",
    "    tag_input.append(datasets[i].tag(\"#X\", \"#gtex_v8\", \"#dataset\",\"#balanced\").describe(\"The input datapoints to the GTEx_V8 dataset.\"))\n",
    "    tag_label.append(labels[i].tag(\"#Y\", \"#gtex_v8\", \"#dataset\",\"#balanced\").describe(\"The input labels to the GTEx_V8 dataset.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3 - Sending our tensors to grid nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_x1 = tag_input[0].send(compute_nodes[0]) # First chunk of dataset to h1\n",
    "shared_x2 = tag_input[1].send(compute_nodes[1]) # Second chunk of dataset to h2\n",
    "\n",
    "shared_y1 = tag_label[0].send(compute_nodes[0]) # First chunk of labels to h1\n",
    "shared_y2 = tag_label[1].send(compute_nodes[1]) # Second chunk of labels to h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor pointers:  (Wrapper)>[PointerTensor | me:48948722904 -> h1:70715698729]\n",
      "\tTags: #dataset #balanced #X #gtex_v8 \n",
      "\tShape: torch.Size([600, 18420])\n",
      "\tDescription: The input datapoints to the GTEx_V8 dataset.... (Wrapper)>[PointerTensor | me:58155984517 -> h2:21280292995]\n",
      "\tTags: #dataset #balanced #X #gtex_v8 \n",
      "\tShape: torch.Size([600, 18420])\n",
      "\tDescription: The input datapoints to the GTEx_V8 dataset....\n",
      "Y tensor pointers:  (Wrapper)>[PointerTensor | me:40701060007 -> h1:68139741794]\n",
      "\tTags: #dataset #balanced #gtex_v8 #Y \n",
      "\tShape: torch.Size([600])\n",
      "\tDescription: The input labels to the GTEx_V8 dataset.... (Wrapper)>[PointerTensor | me:6418339539 -> h2:77907765767]\n",
      "\tTags: #dataset #balanced #gtex_v8 #Y \n",
      "\tShape: torch.Size([600])\n",
      "\tDescription: The input labels to the GTEx_V8 dataset....\n"
     ]
    }
   ],
   "source": [
    "print(\"X tensor pointers: \", shared_x1, shared_x2)\n",
    "print(\"Y tensor pointers: \", shared_y1, shared_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Disconnect nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(compute_nodes)):\n",
    "    compute_nodes[i].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysyft2]",
   "language": "python",
   "name": "conda-env-pysyft2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
