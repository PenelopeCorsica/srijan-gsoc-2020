{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies for helper functions/classes\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from typing import NamedTuple\n",
    "import os.path as path\n",
    "import os\n",
    "import progressbar\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#keras for ML\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.utils import plot_model, normalize\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam, Adadelta\n",
    "from tensorflow.keras.activations import relu, elu, sigmoid\n",
    "\n",
    "#sklearn for preprocessing the data and train-test split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#for plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labels(NamedTuple):\n",
    "    '''\n",
    "    One-hot labeled data\n",
    "    '''\n",
    "    tissue: np.ndarray\n",
    "    sex: np.ndarray\n",
    "    age: np.ndarray\n",
    "    death: np.ndarray\n",
    "        \n",
    "\n",
    "class Genes:\n",
    "    '''\n",
    "    Class to load GTEX samples and gene expressions data\n",
    "    '''\n",
    "    def __init__(self, samples_path: str = '', expressions_path: str = '', problem_type: str = \"classification\"):\n",
    "        self.__set_samples(samples_path)\n",
    "        self.__set_labels(problem_type)\n",
    "        if expressions_path != '':\n",
    "            self.expressions = self.get_expressions(expressions_path)\n",
    "\n",
    "    def __set_samples(self, sample_path: str) -> pd.DataFrame:\n",
    "        self.samples: pd.DataFrame = pq.read_table(sample_path).to_pandas()\n",
    "        self.samples[\"Death\"].fillna(-1.0, inplace = True)\n",
    "        self.samples: pd.DataFrame = self.samples.set_index(\"Name\")\n",
    "        self.samples[\"Sex\"].replace([1, 2], ['male', 'female'], inplace=True)\n",
    "        self.samples[\"Death\"].replace([-1,0,1,2,3,4], ['alive/NA', 'ventilator case', '<10 min.', '<1 hr', '1-24 hr.', '>1 day'], inplace=True)\n",
    "        self.samples = self.samples[~self.samples['Death'].isin(['>1 day'])]\n",
    "        return self.samples\n",
    "\n",
    "    def __set_labels(self, problem_type: str = \"classification\") -> Labels:\n",
    "        self.labels_list = [\"Tissue\", \"Sex\", \"Age\", \"Death\"]\n",
    "        self.labels: pd.DataFrame = self.samples[self.labels_list]\n",
    "        self.drop_list = self.labels_list + [\"Subtissue\", \"Avg_age\"]\n",
    "        \n",
    "        if problem_type == \"classification\":\n",
    "            dummies_df = pd.get_dummies(self.labels[\"Age\"])\n",
    "            print(dummies_df.columns.tolist())\n",
    "            self.Y = dummies_df.values\n",
    "        \n",
    "        if problem_type == \"regression\":\n",
    "            self.Y = self.samples[\"Avg_age\"].values\n",
    "        \n",
    "        return self.Y\n",
    "\n",
    "    def sex_output(self, model):\n",
    "        return Dense(units=self.Y.sex.shape[1], activation='softmax', name='sex_output')(model)\n",
    "\n",
    "    def tissue_output(self, model):\n",
    "        return Dense(units=self.Y.tissue.shape[1], activation='softmax', name='tissue_output')(model)\n",
    "\n",
    "    def death_output(self, model):\n",
    "        return Dense(units=self.Y.death.shape[1], activation='softmax', name='death_output')(model)\n",
    "\n",
    "    def age_output(self, model):\n",
    "        '''\n",
    "        Created an output layer for the keras mode\n",
    "        :param model: keras model\n",
    "        :return: keras Dense layer\n",
    "        '''\n",
    "        return Dense(units=self.Y.age.shape[1], activation='softmax', name='age_output')(model)\n",
    "\n",
    "\n",
    "    def get_expressions(self, expressions_path: str)->pd.DataFrame:\n",
    "        '''\n",
    "        load gene expressions DataFrame\n",
    "        :param expressions_path: path to file with expressions\n",
    "        :return: pandas dataframe with expression\n",
    "        \n",
    "        '''\n",
    "        selected_genes = list(pd.read_csv('../data/gtex/gain_selected_features_tissues_False.csv')['ids'].values)\n",
    "        \n",
    "        if expressions_path.endswith(\".parquet\"):\n",
    "            return pq.read_table(expressions_path).to_pandas().set_index(\"Name\") #[selected_genes]\n",
    "        else:\n",
    "            separator = \",\" if expressions_path.endswith(\".csv\") else \"\\t\"\n",
    "            return pd.read_csv(expressions_path, sep=separator).set_index(\"Name\") #[selected_genes]\n",
    "\n",
    "    def prepare_data(self, normalize_expressions: bool = True)-> np.ndarray:\n",
    "        '''\n",
    "        :param normalize_expressions: if keras should normalize gene expressions\n",
    "        :return: X array to be used as input data by keras\n",
    "        '''\n",
    "        data = self.samples.join(self.expressions, on = \"Name\", how=\"inner\")\n",
    "        ji = data.columns.drop(self.drop_list)\n",
    "        x = data[ji]\n",
    "        \n",
    "        # adding one-hot-encoded tissues and sex\n",
    "        #x = pd.concat([x,pd.get_dummies(data['Tissue'], prefix='tissue'), pd.get_dummies(data['Sex'], prefix='sex')],axis=1)\n",
    "        \n",
    "        steps = [('standardization', StandardScaler()), ('normalization', MinMaxScaler())]\n",
    "        pre_processing_pipeline = Pipeline(steps)\n",
    "        transformed_data = pre_processing_pipeline.fit_transform(x)\n",
    "\n",
    "        x = transformed_data\n",
    "        \n",
    "        print('Data length', len(x))\n",
    "        \n",
    "        return x #normalize(x, axis=0) if normalize_expressions else x\n",
    "    \n",
    "    def get_features_dataframe(self, add_tissues=False):\n",
    "        data = self.samples.join(self.expressions, on = \"Name\", how=\"inner\")\n",
    "        ji = data.columns.drop(self.drop_list)\n",
    "        df = data[ji]\n",
    "        if add_tissues:\n",
    "            df = pd.concat([df,pd.get_dummies(data['Tissue'], prefix='tissue'), pd.get_dummies(data['Sex'], prefix='sex')],axis=1)\n",
    "        x = df.values\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df_normalized = pd.DataFrame(x_scaled, columns=df.columns, index=df.index)\n",
    "        return df_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = '../data/gtex/v8_samples.parquet'\n",
    "expressions_path = '../data/gtex/v8_expressions.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Subtissue</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Death</th>\n",
       "      <th>Avg_age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0126-SM-5GZWZ</th>\n",
       "      <td>Adrenal Gland</td>\n",
       "      <td>Adrenal Gland</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0226-SM-5GZXC</th>\n",
       "      <td>Thyroid</td>\n",
       "      <td>Thyroid</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0326-SM-5GZXO</th>\n",
       "      <td>Lung</td>\n",
       "      <td>Lung</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0426-SM-5GZY1</th>\n",
       "      <td>Spleen</td>\n",
       "      <td>Spleen</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0526-SM-5EGHK</th>\n",
       "      <td>Pancreas</td>\n",
       "      <td>Pancreas</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0626-SM-5EGHL</th>\n",
       "      <td>Esophagus</td>\n",
       "      <td>Esophagus - Muscularis</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0726-SM-5GZYD</th>\n",
       "      <td>Esophagus</td>\n",
       "      <td>Esophagus - Mucosa</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0826-SM-5EGIJ</th>\n",
       "      <td>Esophagus</td>\n",
       "      <td>Esophagus - Gastroesophageal Junction</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-0926-SM-5EGIK</th>\n",
       "      <td>Stomach</td>\n",
       "      <td>Stomach</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-1026-SM-5EGIL</th>\n",
       "      <td>Adipose Tissue</td>\n",
       "      <td>Adipose - Visceral (Omentum)</td>\n",
       "      <td>50-59</td>\n",
       "      <td>male</td>\n",
       "      <td>ventilator case</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Tissue  \\\n",
       "Name                                       \n",
       "GTEX-111CU-0126-SM-5GZWZ   Adrenal Gland   \n",
       "GTEX-111CU-0226-SM-5GZXC         Thyroid   \n",
       "GTEX-111CU-0326-SM-5GZXO            Lung   \n",
       "GTEX-111CU-0426-SM-5GZY1          Spleen   \n",
       "GTEX-111CU-0526-SM-5EGHK        Pancreas   \n",
       "GTEX-111CU-0626-SM-5EGHL       Esophagus   \n",
       "GTEX-111CU-0726-SM-5GZYD       Esophagus   \n",
       "GTEX-111CU-0826-SM-5EGIJ       Esophagus   \n",
       "GTEX-111CU-0926-SM-5EGIK         Stomach   \n",
       "GTEX-111CU-1026-SM-5EGIL  Adipose Tissue   \n",
       "\n",
       "                                                      Subtissue    Age   Sex  \\\n",
       "Name                                                                           \n",
       "GTEX-111CU-0126-SM-5GZWZ                          Adrenal Gland  50-59  male   \n",
       "GTEX-111CU-0226-SM-5GZXC                                Thyroid  50-59  male   \n",
       "GTEX-111CU-0326-SM-5GZXO                                   Lung  50-59  male   \n",
       "GTEX-111CU-0426-SM-5GZY1                                 Spleen  50-59  male   \n",
       "GTEX-111CU-0526-SM-5EGHK                               Pancreas  50-59  male   \n",
       "GTEX-111CU-0626-SM-5EGHL                 Esophagus - Muscularis  50-59  male   \n",
       "GTEX-111CU-0726-SM-5GZYD                     Esophagus - Mucosa  50-59  male   \n",
       "GTEX-111CU-0826-SM-5EGIJ  Esophagus - Gastroesophageal Junction  50-59  male   \n",
       "GTEX-111CU-0926-SM-5EGIK                                Stomach  50-59  male   \n",
       "GTEX-111CU-1026-SM-5EGIL           Adipose - Visceral (Omentum)  50-59  male   \n",
       "\n",
       "                                    Death  Avg_age  \n",
       "Name                                                \n",
       "GTEX-111CU-0126-SM-5GZWZ  ventilator case     54.5  \n",
       "GTEX-111CU-0226-SM-5GZXC  ventilator case     54.5  \n",
       "GTEX-111CU-0326-SM-5GZXO  ventilator case     54.5  \n",
       "GTEX-111CU-0426-SM-5GZY1  ventilator case     54.5  \n",
       "GTEX-111CU-0526-SM-5EGHK  ventilator case     54.5  \n",
       "GTEX-111CU-0626-SM-5EGHL  ventilator case     54.5  \n",
       "GTEX-111CU-0726-SM-5GZYD  ventilator case     54.5  \n",
       "GTEX-111CU-0826-SM-5EGIJ  ventilator case     54.5  \n",
       "GTEX-111CU-0926-SM-5EGIK  ventilator case     54.5  \n",
       "GTEX-111CU-1026-SM-5EGIL  ventilator case     54.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = Genes(samples_path, expressions_path, problem_type=\"regression\")\n",
    "genes.samples.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def optimized_age_model_regression(x_train, x_val, y_train, y_val):\n",
    "    # optimized_age_model(x_train, x_val, y_train, y_val, params: dict):\n",
    "    input_layer = Input(shape=(x_train.shape[1],))\n",
    "    reg = keras.regularizers.l1_l2(l1=0.3, l2=0.3)\n",
    "    mod = Dense(1024, activation=relu)(input_layer) # 196\n",
    "    mod = Dropout(0.1)(mod) \n",
    "    mod = Dense(512, activation=relu)(mod) # 196\n",
    "    mod = Dropout(0.1)(mod)    \n",
    "    mod = Dense(64, activation=relu)(mod) #64\n",
    "    mod = Dropout(0.1)(mod)\n",
    "    \n",
    "    outputs = [Dense(1, name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    #outputs = [Dense(y_train.shape[1], activation='sigmoid', name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    loss = {'age_output': 'mse'}\n",
    "    weights={'age_output': 1.0}\n",
    "    metrics = {'age_output': ['mae', coeff_determination]}\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              loss_weights=weights,\n",
    "              metrics=metrics,\n",
    "                 )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def optimized_age_model_classification(x_train, x_val, y_train, y_val):\n",
    "    # optimized_age_model(x_train, x_val, y_train, y_val, params: dict):\n",
    "    input_layer = Input(shape=(x_train.shape[1],))\n",
    "    reg = keras.regularizers.l1_l2(l1=0, l2=0)\n",
    "    mod = Dense(512, activation=relu, kernel_regularizer=reg, bias_regularizer=reg)(input_layer) # 196\n",
    "    mod = Dropout(0.2)(mod)    \n",
    "    mod = Dense(64, activation=relu, kernel_regularizer=reg, bias_regularizer=reg)(mod) #64\n",
    "    mod = Dropout(0.2)(mod)\n",
    "    \n",
    "    #outputs = [Dense(1, name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    outputs = [Dense(y_train.shape[1], activation='sigmoid', name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    loss = {'age_output': 'categorical_crossentropy'}\n",
    "    weights={'age_output': 1.0}\n",
    "    metrics = {'age_output': 'mae'}\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              loss_weights=weights,\n",
    "              metrics=metrics,\n",
    "                 )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huber(yHat, y, delta=1.):\n",
    "    return np.where(np.abs(y-yHat) < delta,.5*(y-yHat)**2 , delta*(np.abs(y-yHat)-0.5*delta))\n",
    "\n",
    "def transform_to_probas(age_intervals):\n",
    "    class_names = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "    res = []\n",
    "    for a in age_intervals:\n",
    "        non_zero_index = class_names.index(a)\n",
    "        res.append([0 if i != non_zero_index else 1 for i in range(len(class_names))])\n",
    "    return np.array(res)\n",
    "    \n",
    "def transform_to_interval(age_probas):\n",
    "    class_names = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "    return np.array(list(map(lambda p: class_names[np.argmax(p)], age_probas)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length 15343\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12274 samples, validate on 3069 samples\n",
      "Epoch 1/150\n",
      "12274/12274 [==============================] - 10s 782us/sample - loss: 467.1576 - mae: 16.9249 - coeff_determination: -1.8940 - val_loss: 268.3811 - val_mae: 12.9767 - val_coeff_determination: -0.7954\n",
      "Epoch 2/150\n",
      "12274/12274 [==============================] - 8s 662us/sample - loss: 241.0900 - mae: 12.4232 - coeff_determination: -0.4872 - val_loss: 204.5088 - val_mae: 11.2995 - val_coeff_determination: -0.3517\n",
      "Epoch 3/150\n",
      "12274/12274 [==============================] - 8s 631us/sample - loss: 194.7406 - mae: 11.2296 - coeff_determination: -0.2002 - val_loss: 169.2961 - val_mae: 10.2690 - val_coeff_determination: -0.1077\n",
      "Epoch 4/150\n",
      "12274/12274 [==============================] - 8s 617us/sample - loss: 174.3111 - mae: 10.7083 - coeff_determination: -0.0740 - val_loss: 167.1910 - val_mae: 10.8525 - val_coeff_determination: -0.1152\n",
      "Epoch 5/150\n",
      "12274/12274 [==============================] - 8s 625us/sample - loss: 154.2753 - mae: 9.9863 - coeff_determination: 0.0469 - val_loss: 149.8604 - val_mae: 10.2677 - val_coeff_determination: 0.0016\n",
      "Epoch 6/150\n",
      "12274/12274 [==============================] - 8s 618us/sample - loss: 141.6283 - mae: 9.5647 - coeff_determination: 0.1245 - val_loss: 125.4144 - val_mae: 9.0640 - val_coeff_determination: 0.1768\n",
      "Epoch 7/150\n",
      "12274/12274 [==============================] - 9s 710us/sample - loss: 133.9140 - mae: 9.2968 - coeff_determination: 0.1750 - val_loss: 118.1059 - val_mae: 8.6642 - val_coeff_determination: 0.2268\n",
      "Epoch 8/150\n",
      "12274/12274 [==============================] - 10s 781us/sample - loss: 135.7810 - mae: 9.3616 - coeff_determination: 0.1624 - val_loss: 160.7608 - val_mae: 10.8253 - val_coeff_determination: -0.0838\n",
      "Epoch 9/150\n",
      "12274/12274 [==============================] - 9s 773us/sample - loss: 128.7254 - mae: 9.1106 - coeff_determination: 0.2057 - val_loss: 114.9173 - val_mae: 8.3997 - val_coeff_determination: 0.2509\n",
      "Epoch 10/150\n",
      "12274/12274 [==============================] - 9s 701us/sample - loss: 112.9368 - mae: 8.4937 - coeff_determination: 0.3045 - val_loss: 107.9421 - val_mae: 8.4298 - val_coeff_determination: 0.2859\n",
      "Epoch 11/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 114.1656 - mae: 8.5874 - coeff_determination: 0.2964 - val_loss: 117.3480 - val_mae: 8.9378 - val_coeff_determination: 0.2147\n",
      "Epoch 12/150\n",
      "12274/12274 [==============================] - 9s 769us/sample - loss: 110.7475 - mae: 8.4466 - coeff_determination: 0.3185 - val_loss: 98.1334 - val_mae: 8.0018 - val_coeff_determination: 0.3536\n",
      "Epoch 13/150\n",
      "12274/12274 [==============================] - 14s 1ms/sample - loss: 101.9328 - mae: 8.1271 - coeff_determination: 0.3704 - val_loss: 109.3651 - val_mae: 8.5881 - val_coeff_determination: 0.2694\n",
      "Epoch 14/150\n",
      "12274/12274 [==============================] - 9s 749us/sample - loss: 103.7001 - mae: 8.1622 - coeff_determination: 0.3598 - val_loss: 126.0753 - val_mae: 9.2831 - val_coeff_determination: 0.1495\n",
      "Epoch 15/150\n",
      "12274/12274 [==============================] - 11s 868us/sample - loss: 102.8187 - mae: 8.1094 - coeff_determination: 0.3649 - val_loss: 103.6315 - val_mae: 8.2775 - val_coeff_determination: 0.3070\n",
      "Epoch 16/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 108.9779 - mae: 8.3832 - coeff_determination: 0.3234 - val_loss: 101.5817 - val_mae: 7.9604 - val_coeff_determination: 0.3371\n",
      "Epoch 17/150\n",
      "12274/12274 [==============================] - 9s 702us/sample - loss: 101.8185 - mae: 8.0518 - coeff_determination: 0.3724 - val_loss: 99.9319 - val_mae: 8.1256 - val_coeff_determination: 0.3339\n",
      "Epoch 18/150\n",
      "12274/12274 [==============================] - 8s 692us/sample - loss: 97.3943 - mae: 7.9028 - coeff_determination: 0.3971 - val_loss: 91.8978 - val_mae: 7.6639 - val_coeff_determination: 0.3964\n",
      "Epoch 19/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 89.3638 - mae: 7.5355 - coeff_determination: 0.4466 - val_loss: 115.9890 - val_mae: 8.8883 - val_coeff_determination: 0.2146\n",
      "Epoch 20/150\n",
      "12274/12274 [==============================] - 9s 714us/sample - loss: 91.9714 - mae: 7.6970 - coeff_determination: 0.4318 - val_loss: 90.4310 - val_mae: 7.5568 - val_coeff_determination: 0.4048\n",
      "Epoch 21/150\n",
      "12274/12274 [==============================] - 9s 700us/sample - loss: 86.2765 - mae: 7.4108 - coeff_determination: 0.4672 - val_loss: 88.5760 - val_mae: 7.5851 - val_coeff_determination: 0.4127\n",
      "Epoch 22/150\n",
      "12274/12274 [==============================] - 9s 743us/sample - loss: 87.3958 - mae: 7.4696 - coeff_determination: 0.4591 - val_loss: 96.9065 - val_mae: 7.6756 - val_coeff_determination: 0.3628\n",
      "Epoch 23/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 80.8543 - mae: 7.1889 - coeff_determination: 0.5013 - val_loss: 104.8892 - val_mae: 8.3856 - val_coeff_determination: 0.2928\n",
      "Epoch 24/150\n",
      "12274/12274 [==============================] - 9s 703us/sample - loss: 84.6820 - mae: 7.3771 - coeff_determination: 0.4782 - val_loss: 84.1166 - val_mae: 7.2431 - val_coeff_determination: 0.4464\n",
      "Epoch 25/150\n",
      "12274/12274 [==============================] - 9s 702us/sample - loss: 108.4537 - mae: 8.2919 - coeff_determination: 0.3298 - val_loss: 109.2335 - val_mae: 8.6038 - val_coeff_determination: 0.2704\n",
      "Epoch 26/150\n",
      "12274/12274 [==============================] - 9s 763us/sample - loss: 88.2494 - mae: 7.5585 - coeff_determination: 0.4546 - val_loss: 94.0571 - val_mae: 7.8780 - val_coeff_determination: 0.3700\n",
      "Epoch 27/150\n",
      "12274/12274 [==============================] - 9s 703us/sample - loss: 80.2003 - mae: 7.1355 - coeff_determination: 0.5053 - val_loss: 104.9709 - val_mae: 8.3443 - val_coeff_determination: 0.2911\n",
      "Epoch 28/150\n",
      "12274/12274 [==============================] - 11s 920us/sample - loss: 74.2413 - mae: 6.8802 - coeff_determination: 0.5391 - val_loss: 108.0226 - val_mae: 8.4946 - val_coeff_determination: 0.2686\n",
      "Epoch 29/150\n",
      "12274/12274 [==============================] - 9s 699us/sample - loss: 76.9326 - mae: 7.0182 - coeff_determination: 0.5261 - val_loss: 109.5006 - val_mae: 8.2724 - val_coeff_determination: 0.2771\n",
      "Epoch 30/150\n",
      "12274/12274 [==============================] - 9s 703us/sample - loss: 75.8918 - mae: 6.9578 - coeff_determination: 0.5302 - val_loss: 104.1422 - val_mae: 7.9815 - val_coeff_determination: 0.3147\n",
      "Epoch 31/150\n",
      "12274/12274 [==============================] - 10s 780us/sample - loss: 80.4584 - mae: 7.2056 - coeff_determination: 0.5038 - val_loss: 84.4642 - val_mae: 7.3726 - val_coeff_determination: 0.4371\n",
      "Epoch 32/150\n",
      "12274/12274 [==============================] - 8s 669us/sample - loss: 74.6192 - mae: 6.9019 - coeff_determination: 0.5401 - val_loss: 93.6656 - val_mae: 7.8070 - val_coeff_determination: 0.3678\n",
      "Epoch 33/150\n",
      "12274/12274 [==============================] - 9s 706us/sample - loss: 73.4438 - mae: 6.8363 - coeff_determination: 0.5462 - val_loss: 100.7167 - val_mae: 7.9062 - val_coeff_determination: 0.3360\n",
      "Epoch 34/150\n",
      "12274/12274 [==============================] - 9s 712us/sample - loss: 68.0286 - mae: 6.5894 - coeff_determination: 0.5781 - val_loss: 77.3823 - val_mae: 6.9570 - val_coeff_determination: 0.4826\n",
      "Epoch 35/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 75.1978 - mae: 6.9601 - coeff_determination: 0.5355 - val_loss: 84.5602 - val_mae: 7.4091 - val_coeff_determination: 0.4327\n",
      "Epoch 36/150\n",
      "12274/12274 [==============================] - 9s 702us/sample - loss: 78.9436 - mae: 7.0882 - coeff_determination: 0.5146 - val_loss: 88.0493 - val_mae: 7.4248 - val_coeff_determination: 0.4061\n",
      "Epoch 37/150\n",
      "12274/12274 [==============================] - 8s 692us/sample - loss: 64.3389 - mae: 6.3619 - coeff_determination: 0.6016 - val_loss: 84.5508 - val_mae: 7.3180 - val_coeff_determination: 0.4302\n",
      "Epoch 38/150\n",
      "12274/12274 [==============================] - 8s 685us/sample - loss: 66.5213 - mae: 6.4694 - coeff_determination: 0.5866 - val_loss: 164.6348 - val_mae: 10.3366 - val_coeff_determination: -0.0906\n",
      "Epoch 39/150\n",
      "12274/12274 [==============================] - 8s 676us/sample - loss: 71.0254 - mae: 6.6980 - coeff_determination: 0.5592 - val_loss: 78.2029 - val_mae: 6.9367 - val_coeff_determination: 0.4783\n",
      "Epoch 40/150\n",
      "12274/12274 [==============================] - 8s 690us/sample - loss: 74.9890 - mae: 6.9263 - coeff_determination: 0.5346 - val_loss: 93.8138 - val_mae: 7.8164 - val_coeff_determination: 0.3661\n",
      "Epoch 41/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 72.1927 - mae: 6.7834 - coeff_determination: 0.5532 - val_loss: 80.9143 - val_mae: 7.1291 - val_coeff_determination: 0.4590\n",
      "Epoch 42/150\n",
      "12274/12274 [==============================] - 9s 703us/sample - loss: 61.3599 - mae: 6.2323 - coeff_determination: 0.6192 - val_loss: 84.6007 - val_mae: 7.3575 - val_coeff_determination: 0.4284\n",
      "Epoch 43/150\n",
      "12274/12274 [==============================] - 10s 776us/sample - loss: 68.3723 - mae: 6.5937 - coeff_determination: 0.5785 - val_loss: 99.5616 - val_mae: 8.1108 - val_coeff_determination: 0.3243\n",
      "Epoch 44/150\n",
      "12274/12274 [==============================] - 9s 764us/sample - loss: 70.1133 - mae: 6.6907 - coeff_determination: 0.5658 - val_loss: 74.7769 - val_mae: 6.8190 - val_coeff_determination: 0.5017\n",
      "Epoch 45/150\n",
      "12274/12274 [==============================] - 9s 770us/sample - loss: 63.4962 - mae: 6.3487 - coeff_determination: 0.6080 - val_loss: 85.0960 - val_mae: 7.2428 - val_coeff_determination: 0.4381\n",
      "Epoch 46/150\n",
      "12274/12274 [==============================] - 9s 751us/sample - loss: 65.7011 - mae: 6.4522 - coeff_determination: 0.5936 - val_loss: 76.5237 - val_mae: 6.8815 - val_coeff_determination: 0.4895\n",
      "Epoch 47/150\n",
      "12274/12274 [==============================] - 10s 775us/sample - loss: 64.6020 - mae: 6.3902 - coeff_determination: 0.6026 - val_loss: 77.1210 - val_mae: 6.9053 - val_coeff_determination: 0.4839\n",
      "Epoch 48/150\n",
      "12274/12274 [==============================] - 9s 772us/sample - loss: 54.3264 - mae: 5.8301 - coeff_determination: 0.6645 - val_loss: 76.4387 - val_mae: 6.8089 - val_coeff_determination: 0.4919\n",
      "Epoch 49/150\n",
      "12274/12274 [==============================] - 9s 751us/sample - loss: 65.4968 - mae: 6.4654 - coeff_determination: 0.5963 - val_loss: 126.6115 - val_mae: 9.3756 - val_coeff_determination: 0.1340\n",
      "Epoch 50/150\n",
      "12274/12274 [==============================] - 9s 716us/sample - loss: 67.6094 - mae: 6.5489 - coeff_determination: 0.5819 - val_loss: 83.6308 - val_mae: 7.2925 - val_coeff_determination: 0.4345\n",
      "Epoch 51/150\n",
      "12274/12274 [==============================] - 9s 741us/sample - loss: 67.8445 - mae: 6.5679 - coeff_determination: 0.5803 - val_loss: 77.1025 - val_mae: 6.9983 - val_coeff_determination: 0.4836\n",
      "Epoch 52/150\n",
      "12274/12274 [==============================] - 9s 716us/sample - loss: 57.7852 - mae: 6.0564 - coeff_determination: 0.6426 - val_loss: 97.4941 - val_mae: 7.7012 - val_coeff_determination: 0.3550\n",
      "Epoch 53/150\n",
      "12274/12274 [==============================] - 9s 706us/sample - loss: 58.6649 - mae: 6.0832 - coeff_determination: 0.6351 - val_loss: 79.5684 - val_mae: 7.1022 - val_coeff_determination: 0.4656\n",
      "Epoch 54/150\n",
      "12274/12274 [==============================] - 9s 695us/sample - loss: 56.4444 - mae: 5.9340 - coeff_determination: 0.6507 - val_loss: 73.8330 - val_mae: 6.7934 - val_coeff_determination: 0.5041\n",
      "Epoch 55/150\n",
      "12274/12274 [==============================] - 9s 707us/sample - loss: 58.5627 - mae: 6.0893 - coeff_determination: 0.6374 - val_loss: 73.3766 - val_mae: 6.7143 - val_coeff_determination: 0.5093\n",
      "Epoch 56/150\n",
      "12274/12274 [==============================] - 9s 718us/sample - loss: 53.3211 - mae: 5.7986 - coeff_determination: 0.6700 - val_loss: 112.8355 - val_mae: 8.3351 - val_coeff_determination: 0.2502\n",
      "Epoch 57/150\n",
      "12274/12274 [==============================] - 9s 717us/sample - loss: 53.0563 - mae: 5.8047 - coeff_determination: 0.6709 - val_loss: 74.9026 - val_mae: 6.8501 - val_coeff_determination: 0.4948\n",
      "Epoch 58/150\n",
      "12274/12274 [==============================] - 9s 706us/sample - loss: 57.3201 - mae: 6.0114 - coeff_determination: 0.6469 - val_loss: 87.5942 - val_mae: 7.5415 - val_coeff_determination: 0.4078\n",
      "Epoch 59/150\n",
      "12274/12274 [==============================] - 9s 763us/sample - loss: 51.5704 - mae: 5.6863 - coeff_determination: 0.6802 - val_loss: 121.3362 - val_mae: 9.1161 - val_coeff_determination: 0.1680\n",
      "Epoch 60/150\n",
      "12274/12274 [==============================] - 9s 702us/sample - loss: 59.2242 - mae: 6.1206 - coeff_determination: 0.6338 - val_loss: 76.8147 - val_mae: 6.8612 - val_coeff_determination: 0.4904\n",
      "Epoch 61/150\n",
      "12274/12274 [==============================] - 9s 702us/sample - loss: 57.7991 - mae: 6.0347 - coeff_determination: 0.6424 - val_loss: 74.5066 - val_mae: 6.7745 - val_coeff_determination: 0.5002\n",
      "Epoch 62/150\n",
      "12274/12274 [==============================] - 9s 733us/sample - loss: 63.1116 - mae: 6.3473 - coeff_determination: 0.6108 - val_loss: 73.8294 - val_mae: 6.7492 - val_coeff_determination: 0.5119\n",
      "Epoch 63/150\n",
      "12274/12274 [==============================] - 8s 680us/sample - loss: 49.7875 - mae: 5.6128 - coeff_determination: 0.6922 - val_loss: 101.8981 - val_mae: 7.8942 - val_coeff_determination: 0.3221\n",
      "Epoch 64/150\n",
      "12274/12274 [==============================] - 9s 717us/sample - loss: 52.5873 - mae: 5.7583 - coeff_determination: 0.6749 - val_loss: 72.9102 - val_mae: 6.5985 - val_coeff_determination: 0.5144\n",
      "Epoch 65/150\n",
      "12274/12274 [==============================] - 9s 741us/sample - loss: 63.4918 - mae: 6.3278 - coeff_determination: 0.6105 - val_loss: 77.4250 - val_mae: 6.8862 - val_coeff_determination: 0.4856\n",
      "Epoch 66/150\n",
      "12274/12274 [==============================] - 9s 732us/sample - loss: 48.5833 - mae: 5.5259 - coeff_determination: 0.6999 - val_loss: 105.9342 - val_mae: 8.3545 - val_coeff_determination: 0.2778\n",
      "Epoch 67/150\n",
      "12274/12274 [==============================] - 8s 674us/sample - loss: 54.2364 - mae: 5.8842 - coeff_determination: 0.6650 - val_loss: 89.9463 - val_mae: 7.6301 - val_coeff_determination: 0.3881\n",
      "Epoch 68/150\n",
      "12274/12274 [==============================] - 9s 745us/sample - loss: 52.8489 - mae: 5.7546 - coeff_determination: 0.6722 - val_loss: 70.8629 - val_mae: 6.6111 - val_coeff_determination: 0.5239\n",
      "Epoch 69/150\n",
      "12274/12274 [==============================] - 9s 723us/sample - loss: 43.6956 - mae: 5.2203 - coeff_determination: 0.7291 - val_loss: 70.4960 - val_mae: 6.5314 - val_coeff_determination: 0.5297\n",
      "Epoch 70/150\n",
      "12274/12274 [==============================] - 9s 694us/sample - loss: 47.0490 - mae: 5.4560 - coeff_determination: 0.7099 - val_loss: 72.8491 - val_mae: 6.6944 - val_coeff_determination: 0.5075\n",
      "Epoch 71/150\n",
      "12274/12274 [==============================] - 8s 681us/sample - loss: 50.2668 - mae: 5.6361 - coeff_determination: 0.6897 - val_loss: 70.7776 - val_mae: 6.5281 - val_coeff_determination: 0.5274\n",
      "Epoch 72/150\n",
      "12274/12274 [==============================] - 8s 681us/sample - loss: 48.1828 - mae: 5.4988 - coeff_determination: 0.7021 - val_loss: 74.5618 - val_mae: 6.6471 - val_coeff_determination: 0.5063\n",
      "Epoch 73/150\n",
      "12274/12274 [==============================] - 9s 746us/sample - loss: 44.6614 - mae: 5.2729 - coeff_determination: 0.7222 - val_loss: 70.8548 - val_mae: 6.5514 - val_coeff_determination: 0.5247\n",
      "Epoch 74/150\n",
      "12274/12274 [==============================] - 9s 722us/sample - loss: 41.9244 - mae: 5.1316 - coeff_determination: 0.7414 - val_loss: 68.9281 - val_mae: 6.4408 - val_coeff_determination: 0.5383\n",
      "Epoch 75/150\n",
      "12274/12274 [==============================] - 9s 709us/sample - loss: 44.5306 - mae: 5.2852 - coeff_determination: 0.7243 - val_loss: 75.4338 - val_mae: 6.7585 - val_coeff_determination: 0.4995\n",
      "Epoch 76/150\n",
      "12274/12274 [==============================] - 10s 802us/sample - loss: 59.8886 - mae: 6.1386 - coeff_determination: 0.6301 - val_loss: 76.5654 - val_mae: 6.9520 - val_coeff_determination: 0.4856\n",
      "Epoch 77/150\n",
      "12274/12274 [==============================] - 10s 783us/sample - loss: 43.1496 - mae: 5.1937 - coeff_determination: 0.7327 - val_loss: 76.1230 - val_mae: 6.8385 - val_coeff_determination: 0.4858\n",
      "Epoch 78/150\n",
      "12274/12274 [==============================] - 8s 656us/sample - loss: 45.4235 - mae: 5.3605 - coeff_determination: 0.7181 - val_loss: 89.2979 - val_mae: 7.3597 - val_coeff_determination: 0.4086\n",
      "Epoch 79/150\n",
      "12274/12274 [==============================] - 9s 701us/sample - loss: 52.9427 - mae: 5.7914 - coeff_determination: 0.6730 - val_loss: 68.9901 - val_mae: 6.4620 - val_coeff_determination: 0.5370\n",
      "Epoch 80/150\n",
      "12274/12274 [==============================] - 9s 774us/sample - loss: 44.2433 - mae: 5.2897 - coeff_determination: 0.7271 - val_loss: 76.3266 - val_mae: 6.7833 - val_coeff_determination: 0.4930\n",
      "Epoch 81/150\n",
      "12274/12274 [==============================] - 10s 781us/sample - loss: 46.6930 - mae: 5.4248 - coeff_determination: 0.7095 - val_loss: 68.9005 - val_mae: 6.4915 - val_coeff_determination: 0.5385\n",
      "Epoch 82/150\n",
      "12274/12274 [==============================] - 9s 737us/sample - loss: 42.1592 - mae: 5.1233 - coeff_determination: 0.7389 - val_loss: 103.4106 - val_mae: 8.2515 - val_coeff_determination: 0.2945\n",
      "Epoch 83/150\n",
      "12274/12274 [==============================] - 8s 630us/sample - loss: 44.0492 - mae: 5.2621 - coeff_determination: 0.7280 - val_loss: 75.3842 - val_mae: 6.8208 - val_coeff_determination: 0.4924\n",
      "Epoch 84/150\n",
      "12274/12274 [==============================] - 8s 651us/sample - loss: 50.9412 - mae: 5.6722 - coeff_determination: 0.6859 - val_loss: 72.7279 - val_mae: 6.6609 - val_coeff_determination: 0.5105\n",
      "Epoch 85/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 46.6042 - mae: 5.3782 - coeff_determination: 0.7093 - val_loss: 102.3849 - val_mae: 8.2655 - val_coeff_determination: 0.3016\n",
      "Epoch 86/150\n",
      "12274/12274 [==============================] - 8s 671us/sample - loss: 48.7546 - mae: 5.5566 - coeff_determination: 0.6983 - val_loss: 72.3345 - val_mae: 6.6243 - val_coeff_determination: 0.5134\n",
      "Epoch 87/150\n",
      "12274/12274 [==============================] - 8s 657us/sample - loss: 38.6872 - mae: 4.9310 - coeff_determination: 0.7620 - val_loss: 68.8702 - val_mae: 6.4881 - val_coeff_determination: 0.5392\n",
      "Epoch 88/150\n",
      "12274/12274 [==============================] - 8s 665us/sample - loss: 37.1940 - mae: 4.8382 - coeff_determination: 0.7687 - val_loss: 71.7736 - val_mae: 6.6084 - val_coeff_determination: 0.5181\n",
      "Epoch 89/150\n",
      "12274/12274 [==============================] - 8s 666us/sample - loss: 49.3364 - mae: 5.5978 - coeff_determination: 0.6926 - val_loss: 81.5490 - val_mae: 7.0853 - val_coeff_determination: 0.4593\n",
      "Epoch 90/150\n",
      "12274/12274 [==============================] - 8s 671us/sample - loss: 38.7655 - mae: 4.9248 - coeff_determination: 0.7605 - val_loss: 67.8384 - val_mae: 6.4228 - val_coeff_determination: 0.5461\n",
      "Epoch 91/150\n",
      "12274/12274 [==============================] - 9s 708us/sample - loss: 37.4218 - mae: 4.8348 - coeff_determination: 0.7670 - val_loss: 76.2201 - val_mae: 6.9090 - val_coeff_determination: 0.4849\n",
      "Epoch 92/150\n",
      "12274/12274 [==============================] - 8s 665us/sample - loss: 54.7202 - mae: 5.9104 - coeff_determination: 0.6601 - val_loss: 83.5934 - val_mae: 7.1644 - val_coeff_determination: 0.4468\n",
      "Epoch 93/150\n",
      "12274/12274 [==============================] - 9s 701us/sample - loss: 48.6637 - mae: 5.5459 - coeff_determination: 0.6999 - val_loss: 92.1929 - val_mae: 7.6198 - val_coeff_determination: 0.3880\n",
      "Epoch 94/150\n",
      "12274/12274 [==============================] - 8s 683us/sample - loss: 45.5661 - mae: 5.3521 - coeff_determination: 0.7173 - val_loss: 71.6498 - val_mae: 6.6624 - val_coeff_determination: 0.5180\n",
      "Epoch 95/150\n",
      "12274/12274 [==============================] - 8s 673us/sample - loss: 42.7945 - mae: 5.1948 - coeff_determination: 0.7348 - val_loss: 67.5584 - val_mae: 6.3477 - val_coeff_determination: 0.5506\n",
      "Epoch 96/150\n",
      "12274/12274 [==============================] - 8s 675us/sample - loss: 39.4394 - mae: 4.9721 - coeff_determination: 0.7573 - val_loss: 66.5743 - val_mae: 6.3242 - val_coeff_determination: 0.5562\n",
      "Epoch 97/150\n",
      "12274/12274 [==============================] - 9s 708us/sample - loss: 48.6217 - mae: 5.5493 - coeff_determination: 0.6962 - val_loss: 71.6142 - val_mae: 6.6934 - val_coeff_determination: 0.5183\n",
      "Epoch 98/150\n",
      "12274/12274 [==============================] - 8s 682us/sample - loss: 44.3830 - mae: 5.2733 - coeff_determination: 0.7263 - val_loss: 65.7890 - val_mae: 6.3332 - val_coeff_determination: 0.5580\n",
      "Epoch 99/150\n",
      "12274/12274 [==============================] - 8s 639us/sample - loss: 40.4484 - mae: 5.0667 - coeff_determination: 0.7480 - val_loss: 85.5666 - val_mae: 7.1815 - val_coeff_determination: 0.4343\n",
      "Epoch 100/150\n",
      "12274/12274 [==============================] - 8s 630us/sample - loss: 37.5330 - mae: 4.8630 - coeff_determination: 0.7668 - val_loss: 67.6258 - val_mae: 6.3623 - val_coeff_determination: 0.5487\n",
      "Epoch 101/150\n",
      "12274/12274 [==============================] - 8s 655us/sample - loss: 36.6642 - mae: 4.7962 - coeff_determination: 0.7729 - val_loss: 65.9630 - val_mae: 6.2542 - val_coeff_determination: 0.5599\n",
      "Epoch 102/150\n",
      "12274/12274 [==============================] - 8s 629us/sample - loss: 35.1268 - mae: 4.6872 - coeff_determination: 0.7830 - val_loss: 71.3466 - val_mae: 6.6408 - val_coeff_determination: 0.5186\n",
      "Epoch 103/150\n",
      "12274/12274 [==============================] - 8s 621us/sample - loss: 49.1832 - mae: 5.5446 - coeff_determination: 0.6943 - val_loss: 66.3233 - val_mae: 6.3558 - val_coeff_determination: 0.5578\n",
      "Epoch 104/150\n",
      "12274/12274 [==============================] - 8s 617us/sample - loss: 43.4851 - mae: 5.2222 - coeff_determination: 0.7311 - val_loss: 81.1078 - val_mae: 7.0176 - val_coeff_determination: 0.4626\n",
      "Epoch 105/150\n",
      "12274/12274 [==============================] - 8s 626us/sample - loss: 35.9945 - mae: 4.7459 - coeff_determination: 0.7768 - val_loss: 65.3491 - val_mae: 6.2430 - val_coeff_determination: 0.5643\n",
      "Epoch 106/150\n",
      "12274/12274 [==============================] - 8s 637us/sample - loss: 37.5407 - mae: 4.8506 - coeff_determination: 0.7671 - val_loss: 69.6608 - val_mae: 6.5405 - val_coeff_determination: 0.5316\n",
      "Epoch 107/150\n",
      "12274/12274 [==============================] - 8s 657us/sample - loss: 40.3037 - mae: 5.0364 - coeff_determination: 0.7499 - val_loss: 71.8295 - val_mae: 6.5010 - val_coeff_determination: 0.5244\n",
      "Epoch 108/150\n",
      "12274/12274 [==============================] - 9s 716us/sample - loss: 38.0756 - mae: 4.8916 - coeff_determination: 0.7648 - val_loss: 79.1678 - val_mae: 7.0886 - val_coeff_determination: 0.4627\n",
      "Epoch 109/150\n",
      "12274/12274 [==============================] - 8s 653us/sample - loss: 42.2090 - mae: 5.1687 - coeff_determination: 0.7382 - val_loss: 71.1317 - val_mae: 6.5645 - val_coeff_determination: 0.5212\n",
      "Epoch 110/150\n",
      "12274/12274 [==============================] - 8s 637us/sample - loss: 37.9983 - mae: 4.8689 - coeff_determination: 0.7651 - val_loss: 65.4311 - val_mae: 6.2717 - val_coeff_determination: 0.5638\n",
      "Epoch 111/150\n",
      "12274/12274 [==============================] - 8s 657us/sample - loss: 38.6393 - mae: 4.9391 - coeff_determination: 0.7611 - val_loss: 70.6335 - val_mae: 6.5493 - val_coeff_determination: 0.5235\n",
      "Epoch 112/150\n",
      "12274/12274 [==============================] - 8s 670us/sample - loss: 34.7821 - mae: 4.6657 - coeff_determination: 0.7848 - val_loss: 69.7120 - val_mae: 6.4407 - val_coeff_determination: 0.5362\n",
      "Epoch 113/150\n",
      "12274/12274 [==============================] - 8s 667us/sample - loss: 30.9594 - mae: 4.3934 - coeff_determination: 0.8077 - val_loss: 66.3626 - val_mae: 6.3286 - val_coeff_determination: 0.5529\n",
      "Epoch 114/150\n",
      "12274/12274 [==============================] - 8s 648us/sample - loss: 36.0149 - mae: 4.7500 - coeff_determination: 0.7770 - val_loss: 84.9557 - val_mae: 7.3227 - val_coeff_determination: 0.4221\n",
      "Epoch 115/150\n",
      "12274/12274 [==============================] - 8s 651us/sample - loss: 40.3369 - mae: 5.0394 - coeff_determination: 0.7486 - val_loss: 95.0338 - val_mae: 7.6527 - val_coeff_determination: 0.3740\n",
      "Epoch 116/150\n",
      "12274/12274 [==============================] - 8s 692us/sample - loss: 36.1403 - mae: 4.7560 - coeff_determination: 0.7755 - val_loss: 68.9898 - val_mae: 6.4544 - val_coeff_determination: 0.5340\n",
      "Epoch 117/150\n",
      "12274/12274 [==============================] - 9s 710us/sample - loss: 42.7643 - mae: 5.1695 - coeff_determination: 0.7354 - val_loss: 65.1100 - val_mae: 6.2128 - val_coeff_determination: 0.5661\n",
      "Epoch 118/150\n",
      "12274/12274 [==============================] - 9s 759us/sample - loss: 37.6341 - mae: 4.8161 - coeff_determination: 0.7674 - val_loss: 102.4598 - val_mae: 7.9846 - val_coeff_determination: 0.3221\n",
      "Epoch 119/150\n",
      "12274/12274 [==============================] - 9s 753us/sample - loss: 38.0482 - mae: 4.9136 - coeff_determination: 0.7643 - val_loss: 127.7098 - val_mae: 9.1140 - val_coeff_determination: 0.1506\n",
      "Epoch 120/150\n",
      "12274/12274 [==============================] - 9s 718us/sample - loss: 39.8565 - mae: 4.9948 - coeff_determination: 0.7535 - val_loss: 65.2073 - val_mae: 6.2584 - val_coeff_determination: 0.5647\n",
      "Epoch 121/150\n",
      "12274/12274 [==============================] - 9s 728us/sample - loss: 35.6363 - mae: 4.7273 - coeff_determination: 0.7784 - val_loss: 66.2765 - val_mae: 6.3106 - val_coeff_determination: 0.5557\n",
      "Epoch 122/150\n",
      "12274/12274 [==============================] - 9s 723us/sample - loss: 32.8514 - mae: 4.5336 - coeff_determination: 0.7969 - val_loss: 66.6156 - val_mae: 6.2826 - val_coeff_determination: 0.5510\n",
      "Epoch 123/150\n",
      "12274/12274 [==============================] - 9s 719us/sample - loss: 31.4356 - mae: 4.4080 - coeff_determination: 0.8049 - val_loss: 78.9998 - val_mae: 6.9246 - val_coeff_determination: 0.4773\n",
      "Epoch 124/150\n",
      "12274/12274 [==============================] - 9s 701us/sample - loss: 32.6895 - mae: 4.5057 - coeff_determination: 0.7975 - val_loss: 70.1220 - val_mae: 6.5709 - val_coeff_determination: 0.5277\n",
      "Epoch 125/150\n",
      "12274/12274 [==============================] - 8s 674us/sample - loss: 32.1685 - mae: 4.4748 - coeff_determination: 0.8010 - val_loss: 67.2271 - val_mae: 6.3425 - val_coeff_determination: 0.5472\n",
      "Epoch 126/150\n",
      "12274/12274 [==============================] - 9s 694us/sample - loss: 37.8728 - mae: 4.8505 - coeff_determination: 0.7668 - val_loss: 69.6037 - val_mae: 6.4988 - val_coeff_determination: 0.5335\n",
      "Epoch 127/150\n",
      "12274/12274 [==============================] - 8s 677us/sample - loss: 37.3706 - mae: 4.7907 - coeff_determination: 0.7682 - val_loss: 63.6913 - val_mae: 6.1241 - val_coeff_determination: 0.5735\n",
      "Epoch 128/150\n",
      "12274/12274 [==============================] - 8s 647us/sample - loss: 31.6334 - mae: 4.4471 - coeff_determination: 0.8040 - val_loss: 67.9484 - val_mae: 6.3469 - val_coeff_determination: 0.5485\n",
      "Epoch 129/150\n",
      "12274/12274 [==============================] - 8s 650us/sample - loss: 39.4084 - mae: 4.9758 - coeff_determination: 0.7550 - val_loss: 64.6050 - val_mae: 6.2364 - val_coeff_determination: 0.5673\n",
      "Epoch 130/150\n",
      "12274/12274 [==============================] - 8s 642us/sample - loss: 30.4047 - mae: 4.3675 - coeff_determination: 0.8104 - val_loss: 65.8430 - val_mae: 6.2409 - val_coeff_determination: 0.5600\n",
      "Epoch 131/150\n",
      "12274/12274 [==============================] - 8s 656us/sample - loss: 29.5583 - mae: 4.2968 - coeff_determination: 0.8168 - val_loss: 65.7442 - val_mae: 6.1866 - val_coeff_determination: 0.5601\n",
      "Epoch 132/150\n",
      "12274/12274 [==============================] - 8s 648us/sample - loss: 30.4991 - mae: 4.3568 - coeff_determination: 0.8108 - val_loss: 63.1055 - val_mae: 6.1330 - val_coeff_determination: 0.5777\n",
      "Epoch 133/150\n",
      "12274/12274 [==============================] - 8s 656us/sample - loss: 39.8259 - mae: 4.9974 - coeff_determination: 0.7541 - val_loss: 74.0338 - val_mae: 6.6181 - val_coeff_determination: 0.5090\n",
      "Epoch 134/150\n",
      "12274/12274 [==============================] - 8s 649us/sample - loss: 35.9918 - mae: 4.7749 - coeff_determination: 0.7739 - val_loss: 66.3866 - val_mae: 6.3018 - val_coeff_determination: 0.5520\n",
      "Epoch 135/150\n",
      "12274/12274 [==============================] - 8s 634us/sample - loss: 30.2809 - mae: 4.3506 - coeff_determination: 0.8122 - val_loss: 64.3809 - val_mae: 6.1825 - val_coeff_determination: 0.5674\n",
      "Epoch 136/150\n",
      "12274/12274 [==============================] - 8s 632us/sample - loss: 30.5812 - mae: 4.3899 - coeff_determination: 0.8101 - val_loss: 66.7510 - val_mae: 6.2696 - val_coeff_determination: 0.5558\n",
      "Epoch 137/150\n",
      "12274/12274 [==============================] - 8s 631us/sample - loss: 44.6569 - mae: 5.3129 - coeff_determination: 0.7225 - val_loss: 65.1232 - val_mae: 6.1968 - val_coeff_determination: 0.5650\n",
      "Epoch 138/150\n",
      "12274/12274 [==============================] - 8s 652us/sample - loss: 30.7234 - mae: 4.3900 - coeff_determination: 0.8094 - val_loss: 63.1468 - val_mae: 6.1280 - val_coeff_determination: 0.5769\n",
      "Epoch 139/150\n",
      "12274/12274 [==============================] - 7s 606us/sample - loss: 44.7420 - mae: 5.2500 - coeff_determination: 0.7215 - val_loss: 132.3853 - val_mae: 9.6230 - val_coeff_determination: 0.0923\n",
      "Epoch 140/150\n",
      "12274/12274 [==============================] - 8s 615us/sample - loss: 37.7431 - mae: 4.8249 - coeff_determination: 0.7667 - val_loss: 67.1131 - val_mae: 6.3683 - val_coeff_determination: 0.5484\n",
      "Epoch 141/150\n",
      "12274/12274 [==============================] - 8s 634us/sample - loss: 33.2474 - mae: 4.5623 - coeff_determination: 0.7931 - val_loss: 70.5945 - val_mae: 6.5740 - val_coeff_determination: 0.5240\n",
      "Epoch 142/150\n",
      "12274/12274 [==============================] - 8s 634us/sample - loss: 29.9530 - mae: 4.3207 - coeff_determination: 0.8147 - val_loss: 64.1947 - val_mae: 6.1458 - val_coeff_determination: 0.5705\n",
      "Epoch 143/150\n",
      "12274/12274 [==============================] - 7s 610us/sample - loss: 27.3497 - mae: 4.1050 - coeff_determination: 0.8311 - val_loss: 66.2034 - val_mae: 6.1913 - val_coeff_determination: 0.5595\n",
      "Epoch 144/150\n",
      "12274/12274 [==============================] - 8s 657us/sample - loss: 39.8098 - mae: 4.9709 - coeff_determination: 0.7511 - val_loss: 81.9801 - val_mae: 7.0919 - val_coeff_determination: 0.4573\n",
      "Epoch 145/150\n",
      "12274/12274 [==============================] - 8s 635us/sample - loss: 33.2846 - mae: 4.5611 - coeff_determination: 0.7939 - val_loss: 73.7992 - val_mae: 6.6879 - val_coeff_determination: 0.5006\n",
      "Epoch 146/150\n",
      "12274/12274 [==============================] - 9s 708us/sample - loss: 37.6782 - mae: 4.8630 - coeff_determination: 0.7664 - val_loss: 65.3358 - val_mae: 6.1873 - val_coeff_determination: 0.5643\n",
      "Epoch 147/150\n",
      "12274/12274 [==============================] - 9s 715us/sample - loss: 29.6676 - mae: 4.2910 - coeff_determination: 0.8150 - val_loss: 64.4369 - val_mae: 6.1572 - val_coeff_determination: 0.5684\n",
      "Epoch 148/150\n",
      "12274/12274 [==============================] - 8s 670us/sample - loss: 27.7909 - mae: 4.1704 - coeff_determination: 0.8284 - val_loss: 68.1206 - val_mae: 6.3996 - val_coeff_determination: 0.5389\n",
      "Epoch 149/150\n",
      "12274/12274 [==============================] - 9s 746us/sample - loss: 35.9027 - mae: 4.7420 - coeff_determination: 0.7788 - val_loss: 70.2722 - val_mae: 6.5469 - val_coeff_determination: 0.5247\n",
      "Epoch 150/150\n",
      "12274/12274 [==============================] - 9s 703us/sample - loss: 30.0045 - mae: 4.3395 - coeff_determination: 0.8143 - val_loss: 65.7359 - val_mae: 6.2396 - val_coeff_determination: 0.5619\n",
      "R^2 0.6008474719353367\n",
      "Mean squared error 65.73588108455687\n",
      "Mean absolute error 6.239611265518721\n",
      "Huber loss 12.83306417612316\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12274 samples, validate on 3069 samples\n",
      "Epoch 1/150\n",
      "12274/12274 [==============================] - 12s 946us/sample - loss: 519.5862 - mae: 17.9201 - coeff_determination: -2.1664 - val_loss: 266.5960 - val_mae: 13.0059 - val_coeff_determination: -0.8610\n",
      "Epoch 2/150\n",
      "12274/12274 [==============================] - 8s 639us/sample - loss: 266.4038 - mae: 13.0009 - coeff_determination: -0.6392 - val_loss: 206.0790 - val_mae: 11.4815 - val_coeff_determination: -0.4210\n",
      "Epoch 3/150\n",
      "12274/12274 [==============================] - 9s 727us/sample - loss: 219.5487 - mae: 11.9257 - coeff_determination: -0.3494 - val_loss: 182.3483 - val_mae: 11.1597 - val_coeff_determination: -0.2544\n",
      "Epoch 4/150\n",
      "12274/12274 [==============================] - 10s 848us/sample - loss: 187.1032 - mae: 11.0586 - coeff_determination: -0.1479 - val_loss: 151.8748 - val_mae: 9.9395 - val_coeff_determination: -0.0190\n",
      "Epoch 5/150\n",
      "12274/12274 [==============================] - 14s 1ms/sample - loss: 166.8042 - mae: 10.4064 - coeff_determination: -0.0260 - val_loss: 136.9742 - val_mae: 9.4934 - val_coeff_determination: 0.0814\n",
      "Epoch 6/150\n",
      "12274/12274 [==============================] - 11s 928us/sample - loss: 158.5431 - mae: 10.1642 - coeff_determination: 0.0284 - val_loss: 127.0289 - val_mae: 8.8775 - val_coeff_determination: 0.1563\n",
      "Epoch 7/150\n",
      "12274/12274 [==============================] - 8s 682us/sample - loss: 140.5761 - mae: 9.5416 - coeff_determination: 0.1358 - val_loss: 135.6964 - val_mae: 8.9504 - val_coeff_determination: 0.0985\n",
      "Epoch 8/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 155.0378 - mae: 10.0083 - coeff_determination: 0.0473 - val_loss: 157.0484 - val_mae: 10.6976 - val_coeff_determination: -0.0778\n",
      "Epoch 9/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 136.8246 - mae: 9.4166 - coeff_determination: 0.1570 - val_loss: 122.1771 - val_mae: 9.1168 - val_coeff_determination: 0.1749\n",
      "Epoch 10/150\n",
      "12274/12274 [==============================] - 8s 680us/sample - loss: 127.4698 - mae: 9.0848 - coeff_determination: 0.2170 - val_loss: 116.2580 - val_mae: 8.3207 - val_coeff_determination: 0.2232\n",
      "Epoch 11/150\n",
      "12274/12274 [==============================] - 8s 646us/sample - loss: 116.9768 - mae: 8.6940 - coeff_determination: 0.2819 - val_loss: 112.7411 - val_mae: 8.2086 - val_coeff_determination: 0.2463\n",
      "Epoch 12/150\n",
      "12274/12274 [==============================] - 11s 857us/sample - loss: 131.8377 - mae: 9.2039 - coeff_determination: 0.1903 - val_loss: 107.2378 - val_mae: 8.2799 - val_coeff_determination: 0.2778\n",
      "Epoch 13/150\n",
      "12274/12274 [==============================] - 9s 733us/sample - loss: 111.5683 - mae: 8.4503 - coeff_determination: 0.3173 - val_loss: 101.3296 - val_mae: 8.0808 - val_coeff_determination: 0.3158\n",
      "Epoch 14/150\n",
      "12274/12274 [==============================] - 8s 648us/sample - loss: 109.5648 - mae: 8.3987 - coeff_determination: 0.3272 - val_loss: 135.2424 - val_mae: 9.6102 - val_coeff_determination: 0.0710\n",
      "Epoch 15/150\n",
      "12274/12274 [==============================] - 8s 641us/sample - loss: 101.5256 - mae: 8.0756 - coeff_determination: 0.3757 - val_loss: 97.0933 - val_mae: 7.7197 - val_coeff_determination: 0.3480\n",
      "Epoch 16/150\n",
      "12274/12274 [==============================] - 8s 668us/sample - loss: 101.8037 - mae: 8.1049 - coeff_determination: 0.3729 - val_loss: 94.8315 - val_mae: 7.6650 - val_coeff_determination: 0.3600\n",
      "Epoch 17/150\n",
      "12274/12274 [==============================] - 8s 641us/sample - loss: 103.6118 - mae: 8.1606 - coeff_determination: 0.3605 - val_loss: 94.2181 - val_mae: 7.7705 - val_coeff_determination: 0.3617\n",
      "Epoch 18/150\n",
      "12274/12274 [==============================] - 9s 771us/sample - loss: 105.5281 - mae: 8.2031 - coeff_determination: 0.3525 - val_loss: 103.7534 - val_mae: 8.3475 - val_coeff_determination: 0.2906\n",
      "Epoch 19/150\n",
      "12274/12274 [==============================] - 9s 747us/sample - loss: 107.3254 - mae: 8.3042 - coeff_determination: 0.3362 - val_loss: 95.3479 - val_mae: 7.5932 - val_coeff_determination: 0.3612\n",
      "Epoch 20/150\n",
      "12274/12274 [==============================] - 8s 660us/sample - loss: 101.1999 - mae: 8.0818 - coeff_determination: 0.3788 - val_loss: 100.5202 - val_mae: 8.1599 - val_coeff_determination: 0.3121\n",
      "Epoch 21/150\n",
      "12274/12274 [==============================] - 8s 684us/sample - loss: 92.7890 - mae: 7.7397 - coeff_determination: 0.4298 - val_loss: 91.4485 - val_mae: 7.6476 - val_coeff_determination: 0.3768\n",
      "Epoch 22/150\n",
      "12274/12274 [==============================] - 8s 687us/sample - loss: 85.3319 - mae: 7.3900 - coeff_determination: 0.4751 - val_loss: 89.0378 - val_mae: 7.3743 - val_coeff_determination: 0.3975\n",
      "Epoch 23/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 84.2397 - mae: 7.3330 - coeff_determination: 0.4836 - val_loss: 94.3963 - val_mae: 7.5623 - val_coeff_determination: 0.3601\n",
      "Epoch 24/150\n",
      "12274/12274 [==============================] - 8s 687us/sample - loss: 108.2089 - mae: 8.3354 - coeff_determination: 0.3349 - val_loss: 108.3529 - val_mae: 8.6094 - val_coeff_determination: 0.2552\n",
      "Epoch 25/150\n",
      "12274/12274 [==============================] - 8s 666us/sample - loss: 78.9712 - mae: 7.0805 - coeff_determination: 0.5167 - val_loss: 85.4693 - val_mae: 7.2543 - val_coeff_determination: 0.4204\n",
      "Epoch 26/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 90.1449 - mae: 7.5719 - coeff_determination: 0.4467 - val_loss: 83.8889 - val_mae: 7.2697 - val_coeff_determination: 0.4312\n",
      "Epoch 27/150\n",
      "12274/12274 [==============================] - 8s 670us/sample - loss: 81.1963 - mae: 7.2093 - coeff_determination: 0.5017 - val_loss: 82.4854 - val_mae: 7.1800 - val_coeff_determination: 0.4371\n",
      "Epoch 28/150\n",
      "12274/12274 [==============================] - 8s 687us/sample - loss: 84.2050 - mae: 7.3237 - coeff_determination: 0.4841 - val_loss: 132.6911 - val_mae: 9.1245 - val_coeff_determination: 0.1003\n",
      "Epoch 29/150\n",
      "12274/12274 [==============================] - 8s 677us/sample - loss: 96.9425 - mae: 7.9236 - coeff_determination: 0.4017 - val_loss: 83.1307 - val_mae: 7.1239 - val_coeff_determination: 0.4393\n",
      "Epoch 30/150\n",
      "12274/12274 [==============================] - 8s 665us/sample - loss: 77.4029 - mae: 7.0171 - coeff_determination: 0.5239 - val_loss: 91.0283 - val_mae: 7.3925 - val_coeff_determination: 0.3831\n",
      "Epoch 31/150\n",
      "12274/12274 [==============================] - 8s 675us/sample - loss: 71.7645 - mae: 6.7452 - coeff_determination: 0.5590 - val_loss: 82.1404 - val_mae: 7.0608 - val_coeff_determination: 0.4404\n",
      "Epoch 32/150\n",
      "12274/12274 [==============================] - 8s 671us/sample - loss: 98.2637 - mae: 7.9087 - coeff_determination: 0.3977 - val_loss: 87.3051 - val_mae: 7.3073 - val_coeff_determination: 0.4108\n",
      "Epoch 33/150\n",
      "12274/12274 [==============================] - 8s 676us/sample - loss: 85.1631 - mae: 7.4057 - coeff_determination: 0.4762 - val_loss: 92.0274 - val_mae: 7.7370 - val_coeff_determination: 0.3718\n",
      "Epoch 34/150\n",
      "12274/12274 [==============================] - 8s 675us/sample - loss: 73.8975 - mae: 6.8488 - coeff_determination: 0.5456 - val_loss: 104.9436 - val_mae: 8.4103 - val_coeff_determination: 0.2729\n",
      "Epoch 35/150\n",
      "12274/12274 [==============================] - 8s 664us/sample - loss: 70.5031 - mae: 6.7227 - coeff_determination: 0.5676 - val_loss: 79.8666 - val_mae: 6.9707 - val_coeff_determination: 0.4580\n",
      "Epoch 36/150\n",
      "12274/12274 [==============================] - 8s 670us/sample - loss: 66.8069 - mae: 6.5288 - coeff_determination: 0.5878 - val_loss: 76.7323 - val_mae: 6.8984 - val_coeff_determination: 0.4771\n",
      "Epoch 37/150\n",
      "12274/12274 [==============================] - 8s 666us/sample - loss: 69.1279 - mae: 6.6106 - coeff_determination: 0.5766 - val_loss: 81.5736 - val_mae: 7.0344 - val_coeff_determination: 0.4460\n",
      "Epoch 38/150\n",
      "12274/12274 [==============================] - 8s 679us/sample - loss: 65.5898 - mae: 6.4381 - coeff_determination: 0.5967 - val_loss: 105.2411 - val_mae: 8.3753 - val_coeff_determination: 0.2677\n",
      "Epoch 39/150\n",
      "12274/12274 [==============================] - 8s 669us/sample - loss: 71.4549 - mae: 6.7694 - coeff_determination: 0.5599 - val_loss: 80.4819 - val_mae: 7.1247 - val_coeff_determination: 0.4483\n",
      "Epoch 40/150\n",
      "12274/12274 [==============================] - 8s 673us/sample - loss: 77.3157 - mae: 7.0165 - coeff_determination: 0.5240 - val_loss: 95.1717 - val_mae: 7.9677 - val_coeff_determination: 0.3451\n",
      "Epoch 41/150\n",
      "12274/12274 [==============================] - 8s 667us/sample - loss: 69.1400 - mae: 6.6211 - coeff_determination: 0.5749 - val_loss: 86.1478 - val_mae: 7.2425 - val_coeff_determination: 0.4155\n",
      "Epoch 42/150\n",
      "12274/12274 [==============================] - 8s 667us/sample - loss: 68.1352 - mae: 6.5742 - coeff_determination: 0.5804 - val_loss: 83.8032 - val_mae: 7.2973 - val_coeff_determination: 0.4233\n",
      "Epoch 43/150\n",
      "12274/12274 [==============================] - 8s 675us/sample - loss: 62.5011 - mae: 6.2878 - coeff_determination: 0.6142 - val_loss: 73.9976 - val_mae: 6.7043 - val_coeff_determination: 0.4950\n",
      "Epoch 44/150\n",
      "12274/12274 [==============================] - 8s 665us/sample - loss: 65.2092 - mae: 6.4306 - coeff_determination: 0.5987 - val_loss: 84.7070 - val_mae: 7.2046 - val_coeff_determination: 0.4239\n",
      "Epoch 45/150\n",
      "12274/12274 [==============================] - 8s 690us/sample - loss: 66.2996 - mae: 6.4912 - coeff_determination: 0.5928 - val_loss: 77.7213 - val_mae: 6.9389 - val_coeff_determination: 0.4689\n",
      "Epoch 46/150\n",
      "12274/12274 [==============================] - 11s 870us/sample - loss: 61.9606 - mae: 6.2631 - coeff_determination: 0.6182 - val_loss: 76.5331 - val_mae: 6.8112 - val_coeff_determination: 0.4804\n",
      "Epoch 47/150\n",
      "12274/12274 [==============================] - 10s 787us/sample - loss: 69.7195 - mae: 6.6881 - coeff_determination: 0.5720 - val_loss: 79.4880 - val_mae: 7.0975 - val_coeff_determination: 0.4547\n",
      "Epoch 48/150\n",
      "12274/12274 [==============================] - 10s 813us/sample - loss: 68.5512 - mae: 6.5921 - coeff_determination: 0.5782 - val_loss: 100.2802 - val_mae: 8.1255 - val_coeff_determination: 0.3079\n",
      "Epoch 49/150\n",
      "12274/12274 [==============================] - 9s 749us/sample - loss: 59.4648 - mae: 6.1245 - coeff_determination: 0.6344 - val_loss: 86.2908 - val_mae: 7.2358 - val_coeff_determination: 0.4136\n",
      "Epoch 50/150\n",
      "12274/12274 [==============================] - 9s 763us/sample - loss: 57.3422 - mae: 6.0303 - coeff_determination: 0.6469 - val_loss: 71.8831 - val_mae: 6.5872 - val_coeff_determination: 0.5105\n",
      "Epoch 51/150\n",
      "12274/12274 [==============================] - 9s 766us/sample - loss: 60.4508 - mae: 6.1812 - coeff_determination: 0.6260 - val_loss: 91.7168 - val_mae: 7.6674 - val_coeff_determination: 0.3655\n",
      "Epoch 52/150\n",
      "12274/12274 [==============================] - 12s 998us/sample - loss: 58.1364 - mae: 6.0684 - coeff_determination: 0.6427 - val_loss: 71.0158 - val_mae: 6.5503 - val_coeff_determination: 0.5150\n",
      "Epoch 53/150\n",
      "12274/12274 [==============================] - 13s 1ms/sample - loss: 77.0820 - mae: 7.0135 - coeff_determination: 0.5230 - val_loss: 127.8300 - val_mae: 9.4253 - val_coeff_determination: 0.1101\n",
      "Epoch 54/150\n",
      "12274/12274 [==============================] - 10s 802us/sample - loss: 64.3962 - mae: 6.4066 - coeff_determination: 0.6056 - val_loss: 78.6313 - val_mae: 7.0259 - val_coeff_determination: 0.4603\n",
      "Epoch 55/150\n",
      "12274/12274 [==============================] - 10s 836us/sample - loss: 61.2088 - mae: 6.2423 - coeff_determination: 0.6246 - val_loss: 70.8001 - val_mae: 6.5557 - val_coeff_determination: 0.5184\n",
      "Epoch 56/150\n",
      "12274/12274 [==============================] - 9s 754us/sample - loss: 52.8253 - mae: 5.7827 - coeff_determination: 0.6753 - val_loss: 72.2093 - val_mae: 6.6210 - val_coeff_determination: 0.5063\n",
      "Epoch 57/150\n",
      "12274/12274 [==============================] - 15s 1ms/sample - loss: 58.1305 - mae: 6.0865 - coeff_determination: 0.6422 - val_loss: 76.2679 - val_mae: 6.7631 - val_coeff_determination: 0.4803\n",
      "Epoch 58/150\n",
      "12274/12274 [==============================] - 9s 724us/sample - loss: 53.0070 - mae: 5.7851 - coeff_determination: 0.6736 - val_loss: 70.2647 - val_mae: 6.5357 - val_coeff_determination: 0.5208\n",
      "Epoch 59/150\n",
      "12274/12274 [==============================] - 9s 744us/sample - loss: 58.2673 - mae: 6.0542 - coeff_determination: 0.6402 - val_loss: 82.6959 - val_mae: 7.0834 - val_coeff_determination: 0.4383\n",
      "Epoch 60/150\n",
      "12274/12274 [==============================] - 9s 732us/sample - loss: 57.8188 - mae: 6.0449 - coeff_determination: 0.6442 - val_loss: 95.8014 - val_mae: 7.8844 - val_coeff_determination: 0.3401\n",
      "Epoch 61/150\n",
      "12274/12274 [==============================] - 9s 744us/sample - loss: 61.4742 - mae: 6.2565 - coeff_determination: 0.6222 - val_loss: 82.1251 - val_mae: 7.0631 - val_coeff_determination: 0.4416\n",
      "Epoch 62/150\n",
      "12274/12274 [==============================] - 9s 748us/sample - loss: 49.4896 - mae: 5.5963 - coeff_determination: 0.6944 - val_loss: 75.3236 - val_mae: 6.8435 - val_coeff_determination: 0.4821\n",
      "Epoch 63/150\n",
      "12274/12274 [==============================] - 9s 755us/sample - loss: 57.7445 - mae: 6.0324 - coeff_determination: 0.6452 - val_loss: 68.4527 - val_mae: 6.4356 - val_coeff_determination: 0.5352\n",
      "Epoch 64/150\n",
      "12274/12274 [==============================] - 9s 767us/sample - loss: 57.1292 - mae: 6.0088 - coeff_determination: 0.6508 - val_loss: 106.4673 - val_mae: 8.3779 - val_coeff_determination: 0.2589\n",
      "Epoch 65/150\n",
      "12274/12274 [==============================] - 9s 766us/sample - loss: 60.3178 - mae: 6.1879 - coeff_determination: 0.6293 - val_loss: 68.7631 - val_mae: 6.3857 - val_coeff_determination: 0.5330\n",
      "Epoch 66/150\n",
      "12274/12274 [==============================] - 10s 821us/sample - loss: 50.8593 - mae: 5.6708 - coeff_determination: 0.6867 - val_loss: 86.2961 - val_mae: 7.2465 - val_coeff_determination: 0.4148\n",
      "Epoch 67/150\n",
      "12274/12274 [==============================] - 10s 813us/sample - loss: 54.1621 - mae: 5.8271 - coeff_determination: 0.6671 - val_loss: 69.8684 - val_mae: 6.5059 - val_coeff_determination: 0.5230\n",
      "Epoch 68/150\n",
      "12274/12274 [==============================] - 10s 846us/sample - loss: 47.1055 - mae: 5.4368 - coeff_determination: 0.7103 - val_loss: 70.9809 - val_mae: 6.4942 - val_coeff_determination: 0.5173\n",
      "Epoch 69/150\n",
      "12274/12274 [==============================] - 11s 866us/sample - loss: 50.7562 - mae: 5.6848 - coeff_determination: 0.6869 - val_loss: 68.5956 - val_mae: 6.4652 - val_coeff_determination: 0.5314\n",
      "Epoch 70/150\n",
      "12274/12274 [==============================] - 10s 817us/sample - loss: 50.9951 - mae: 5.6591 - coeff_determination: 0.6856 - val_loss: 71.9166 - val_mae: 6.5598 - val_coeff_determination: 0.5128\n",
      "Epoch 71/150\n",
      "12274/12274 [==============================] - 10s 778us/sample - loss: 46.0415 - mae: 5.3820 - coeff_determination: 0.7164 - val_loss: 73.0275 - val_mae: 6.6893 - val_coeff_determination: 0.4995\n",
      "Epoch 72/150\n",
      "12274/12274 [==============================] - 9s 774us/sample - loss: 54.6972 - mae: 5.8996 - coeff_determination: 0.6634 - val_loss: 69.0669 - val_mae: 6.4067 - val_coeff_determination: 0.5291\n",
      "Epoch 73/150\n",
      "12274/12274 [==============================] - 10s 792us/sample - loss: 60.3911 - mae: 6.2073 - coeff_determination: 0.6287 - val_loss: 68.0676 - val_mae: 6.3794 - val_coeff_determination: 0.5373\n",
      "Epoch 74/150\n",
      "12274/12274 [==============================] - 10s 789us/sample - loss: 45.1770 - mae: 5.3341 - coeff_determination: 0.7224 - val_loss: 67.2314 - val_mae: 6.3418 - val_coeff_determination: 0.5426\n",
      "Epoch 75/150\n",
      "12274/12274 [==============================] - 10s 804us/sample - loss: 44.5752 - mae: 5.2714 - coeff_determination: 0.7269 - val_loss: 66.2105 - val_mae: 6.2978 - val_coeff_determination: 0.5481\n",
      "Epoch 76/150\n",
      "12274/12274 [==============================] - 11s 877us/sample - loss: 46.5756 - mae: 5.3978 - coeff_determination: 0.7137 - val_loss: 73.4446 - val_mae: 6.5465 - val_coeff_determination: 0.5011\n",
      "Epoch 77/150\n",
      "12274/12274 [==============================] - 11s 925us/sample - loss: 45.8676 - mae: 5.3809 - coeff_determination: 0.7182 - val_loss: 85.5862 - val_mae: 7.4104 - val_coeff_determination: 0.4123\n",
      "Epoch 78/150\n",
      "12274/12274 [==============================] - 11s 935us/sample - loss: 49.6094 - mae: 5.5930 - coeff_determination: 0.6948 - val_loss: 67.4149 - val_mae: 6.3295 - val_coeff_determination: 0.5394\n",
      "Epoch 79/150\n",
      "12274/12274 [==============================] - 12s 980us/sample - loss: 47.8421 - mae: 5.5085 - coeff_determination: 0.7061 - val_loss: 76.4260 - val_mae: 6.7605 - val_coeff_determination: 0.4789\n",
      "Epoch 80/150\n",
      "12274/12274 [==============================] - 11s 864us/sample - loss: 46.1525 - mae: 5.3628 - coeff_determination: 0.7159 - val_loss: 70.0347 - val_mae: 6.5316 - val_coeff_determination: 0.5199\n",
      "Epoch 81/150\n",
      "12274/12274 [==============================] - 10s 814us/sample - loss: 50.2832 - mae: 5.6092 - coeff_determination: 0.6921 - val_loss: 69.7590 - val_mae: 6.4363 - val_coeff_determination: 0.5227\n",
      "Epoch 82/150\n",
      "12274/12274 [==============================] - 11s 861us/sample - loss: 48.5532 - mae: 5.5504 - coeff_determination: 0.7003 - val_loss: 82.0443 - val_mae: 7.1153 - val_coeff_determination: 0.4398\n",
      "Epoch 83/150\n",
      "12274/12274 [==============================] - 10s 804us/sample - loss: 45.5931 - mae: 5.3397 - coeff_determination: 0.7193 - val_loss: 73.6498 - val_mae: 6.6431 - val_coeff_determination: 0.4922\n",
      "Epoch 84/150\n",
      "12274/12274 [==============================] - 10s 795us/sample - loss: 42.3300 - mae: 5.1507 - coeff_determination: 0.7391 - val_loss: 69.3257 - val_mae: 6.4377 - val_coeff_determination: 0.5269\n",
      "Epoch 85/150\n",
      "12274/12274 [==============================] - 10s 794us/sample - loss: 49.3039 - mae: 5.5758 - coeff_determination: 0.6972 - val_loss: 69.6872 - val_mae: 6.5071 - val_coeff_determination: 0.5248\n",
      "Epoch 86/150\n",
      "12274/12274 [==============================] - 10s 784us/sample - loss: 48.2943 - mae: 5.5183 - coeff_determination: 0.7016 - val_loss: 68.3228 - val_mae: 6.4243 - val_coeff_determination: 0.5333\n",
      "Epoch 87/150\n",
      "12274/12274 [==============================] - 9s 759us/sample - loss: 45.2066 - mae: 5.3555 - coeff_determination: 0.7213 - val_loss: 68.1626 - val_mae: 6.3608 - val_coeff_determination: 0.5367\n",
      "Epoch 88/150\n",
      "12274/12274 [==============================] - 10s 827us/sample - loss: 53.1586 - mae: 5.8060 - coeff_determination: 0.6712 - val_loss: 132.9850 - val_mae: 9.4892 - val_coeff_determination: 0.0762\n",
      "Epoch 89/150\n",
      "12274/12274 [==============================] - 10s 808us/sample - loss: 47.5227 - mae: 5.4877 - coeff_determination: 0.7042 - val_loss: 73.0767 - val_mae: 6.6843 - val_coeff_determination: 0.4961\n",
      "Epoch 90/150\n",
      "12274/12274 [==============================] - 9s 764us/sample - loss: 42.1982 - mae: 5.1489 - coeff_determination: 0.7393 - val_loss: 64.8618 - val_mae: 6.2257 - val_coeff_determination: 0.5559\n",
      "Epoch 91/150\n",
      "12274/12274 [==============================] - 8s 677us/sample - loss: 42.9824 - mae: 5.1800 - coeff_determination: 0.7336 - val_loss: 65.9535 - val_mae: 6.3219 - val_coeff_determination: 0.5535\n",
      "Epoch 92/150\n",
      "12274/12274 [==============================] - 9s 725us/sample - loss: 42.7960 - mae: 5.1647 - coeff_determination: 0.7364 - val_loss: 67.6647 - val_mae: 6.3386 - val_coeff_determination: 0.5358\n",
      "Epoch 93/150\n",
      " 2304/12274 [====>.........................] - ETA: 6s - loss: 43.8935 - mae: 5.2681 - coeff_determination: 0.7331"
     ]
    }
   ],
   "source": [
    "genes = Genes(samples_path, expressions_path, problem_type=\"regression\")\n",
    "X = genes.prepare_data(True)\n",
    "Y = genes.Y\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "huber_loss = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = optimized_age_model_regression(X[train], X[test], Y[train], Y[test])\n",
    "    model.fit(X[train], Y[train], validation_data=[X[test], Y[test]], epochs=150, batch_size=256, verbose=1)\n",
    "    predictions = model.predict(X[test])\n",
    "    test_y = Y[test]\n",
    "\n",
    "    print(\"R^2\", r2_score(test_y, predictions))\n",
    "    print(\"Mean squared error\", mean_squared_error(test_y, predictions))\n",
    "    print(\"Mean absolute error\", mean_absolute_error(test_y, predictions))\n",
    "    print('Huber loss', np.mean(Huber(test_y, predictions)))\n",
    "\n",
    "    rmse.append(mean_squared_error(test_y, predictions))\n",
    "    mae.append(mean_absolute_error(test_y, predictions))\n",
    "    r2.append(r2_score(test_y, predictions))\n",
    "    huber_loss.append(np.mean(Huber(test_y, predictions)))\n",
    "      \n",
    "print('Mean MSE = ', np.mean(rmse))\n",
    "print('Mean MAE = ', np.mean(mae))\n",
    "print('Mean R2 = ', np.mean(r2))\n",
    "print('Mean Huber Loss = ', np.mean(huber_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 18420)]           0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               9431552   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 9,464,774\n",
      "Trainable params: 9,464,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.3252804141501294\n",
      "F1 Score 0.15967541163359217\n",
      "Precision 0.10580734782967972\n",
      "Recall 0.3252804141501294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 18420)]           0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               9431552   \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 9,464,774\n",
      "Trainable params: 9,464,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.3425366695427092\n",
      "F1 Score 0.17479056273580407\n",
      "Precision 0.11733136998141118\n",
      "Recall 0.3425366695427092\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 18420)]           0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               9431552   \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 9,464,774\n",
      "Trainable params: 9,464,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.358457997698504\n",
      "F1 Score 0.23575031262580737\n",
      "Precision 0.22139084642619294\n",
      "Recall 0.358457997698504\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 18420)]           0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               9431552   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 9,464,774\n",
      "Trainable params: 9,464,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.37744533947065595\n",
      "F1 Score 0.2977457249576557\n",
      "Precision 0.245912453987849\n",
      "Recall 0.37744533947065595\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 18420)]           0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               9431552   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 9,464,774\n",
      "Trainable params: 9,464,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.39729574223245107\n",
      "F1 Score 0.3181785906766393\n",
      "Precision 0.2658258015861633\n",
      "Recall 0.39729574223245107\n",
      "Mean Accuracy =  0.36020323261888987\n",
      "Mean F1 Score =  0.23722812052589975\n",
      "Mean Precision =  0.19125356396225923\n",
      "Mean Recall =  0.36020323261888987\n"
     ]
    }
   ],
   "source": [
    "genes = Genes(samples_path, expressions_path, problem_type=\"classification\")\n",
    "X = genes.get_features_dataframe().values\n",
    "Y = genes.Y\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=87)\n",
    "\n",
    "accuracies = []\n",
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for train, test in kfold.split(X, transform_to_interval(Y)):\n",
    "    model = optimized_age_model_classification(X[train], X[test], Y[train], Y[test])\n",
    "    model.fit(X[train], Y[train], validation_data=[X[test], Y[test]], epochs=5, batch_size=256, verbose=0, class_weight=class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(transform_to_interval(Y)),\n",
    "                                             transform_to_interval(Y)))\n",
    "    predictions = transform_to_interval(model.predict(X[test]))\n",
    "    test_y = transform_to_interval(Y[test])\n",
    "\n",
    "    print(\"Accuracy\", accuracy_score(test_y, predictions))\n",
    "    print(\"F1 Score\", f1_score(test_y, predictions, average='weighted'))\n",
    "    print(\"Precision\", precision_score(test_y, predictions, average='weighted'))\n",
    "    print('Recall', recall_score(test_y, predictions, average='weighted'))\n",
    "\n",
    "    accuracies.append(accuracy_score(test_y, predictions))\n",
    "    f1s.append(f1_score(test_y, predictions, average='weighted'))\n",
    "    precisions.append(precision_score(test_y, predictions, average='weighted'))\n",
    "    recalls.append(recall_score(test_y, predictions, average='weighted'))\n",
    "\n",
    "print('Mean Accuracy = ', np.mean(accuracies))\n",
    "print('Mean F1 Score = ', np.mean(f1s))\n",
    "print('Mean Precision = ', np.mean(precisions))\n",
    "print('Mean Recall = ', np.mean(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
