{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Federated Learning - GTEx_V8 Example</h1>\n",
    "<h2>Populate remote PyGrid nodes with labeled tensors </h2>\n",
    "In this notebook, we will populate our PyGrid nodes with labeled data so that it will be used later by people interested in train models.\n",
    "\n",
    "**NOTE:** At the time of running this notebook, we were running the grid components in background mode.  \n",
    "\n",
    "Components:\n",
    " - PyGrid Network (http://localhost:5000)\n",
    " - PyGrid Node h1 (http://localhost:3000)\n",
    " - PyGrid Node h2 (http://localhost:3001)\n",
    " \n",
    "Code implementation for this notebook has been referred from <a href=\"https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/grid/federated_learning/mnist/Fed.Learning%20MNIST%20%5B%20Part-1%20%5D%20-%20Populate%20a%20Grid%20Network%20(%20Dataset%20).ipynb\">Fed.Learning MNIST [ Part-1 ] - Populate a Grid Network ( Dataset )</a> tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "#########<syft==0.2.8>#######################\n",
    "# # Dynamic FL -->\n",
    "from syft.grid.clients.data_centric_fl_client import DataCentricFLClient\n",
    "\n",
    "# #Static FL -->\n",
    "from syft.grid.clients.model_centric_fl_client import ModelCentricFLClient\n",
    "#############################################\n",
    "\n",
    "#########<syft==0.2.6>#######################\n",
    "# Dynamic FL -->\n",
    "# from syft.grid.clients.dynamic_fl_client import DynamicFLClient\n",
    "\n",
    "#Static FL -->\n",
    "# from syft.grid.clients.static_fl_client import StaticFLClient\n",
    "#############################################\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "# import tqdm\n",
    "# from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sy.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setup config</h2>\n",
    "Init hook, connect with grid nodes, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Connect directly to grid nodes\n",
    "nodes = [\"ws://0.0.0.0:3000/\",\n",
    "         \"ws://0.0.0.0:3001/\"]\n",
    "\n",
    "compute_nodes = []\n",
    "for node in nodes:\n",
    "    # For syft 0.2.8 --> replace DynamicFLClient with DataCentricFLClient\n",
    "    compute_nodes.append( DataCentricFLClient(hook, node) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Federated Worker id:h1>, <Federated Worker id:h2>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Dataset\n",
    "\n",
    "The code below will load GTEx data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajverma/anaconda3/envs/pysyft_v028/lib/python3.6/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/balanced/numpy_files/'\n",
    "shared_x1 = np.load(DATA_PATH + 'shared_x1.npy') # First chunk of dataset \n",
    "shared_x2 = np.load(DATA_PATH + 'shared_x2.npy') # Second chunk of dataset \n",
    "\n",
    "shared_y1 = np.load(DATA_PATH + 'shared_y1.npy') # First chunk of labels \n",
    "shared_y2 = np.load(DATA_PATH + 'shared_y2.npy') # Second chunk of labels \n",
    "\n",
    "# Convert numpy array to torch tensors -->\n",
    "shared_x1 = torch.from_numpy(shared_x1)\n",
    "shared_x2 = torch.from_numpy(shared_x2)\n",
    "shared_y1 = torch.from_numpy(shared_y1)\n",
    "shared_y2 = torch.from_numpy(shared_y2)\n",
    "\n",
    "shared_x1 = torch.tensor(shared_x1, dtype=torch.float32)\n",
    "shared_x2 = torch.tensor(shared_x2, dtype=torch.float32)\n",
    "shared_y1 = torch.tensor(shared_y1, dtype=torch.int64)\n",
    "shared_y2 = torch.tensor(shared_y2, dtype=torch.int64)\n",
    "\n",
    "datasets  = [shared_x1, shared_x2]\n",
    "labels = [shared_y1, shared_y2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below using centralized way (full data) --->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training loss: 0.001493217945098877  | Training Accuracy: 0.16666666666666666\n",
      "Epoch: 1 Training loss: 0.0014930233359336854  | Training Accuracy: 0.1675\n",
      "Epoch: 2 Training loss: 0.0014896153410275776  | Training Accuracy: 0.24666666666666667\n",
      "Epoch: 3 Training loss: 0.001487082044283549  | Training Accuracy: 0.1975\n",
      "Epoch: 4 Training loss: 0.0014871734380722047  | Training Accuracy: 0.2075\n",
      "Epoch: 5 Training loss: 0.00148458997408549  | Training Accuracy: 0.19833333333333333\n",
      "Epoch: 6 Training loss: 0.0014761630694071451  | Training Accuracy: 0.25\n",
      "Epoch: 7 Training loss: 0.001480031708876292  | Training Accuracy: 0.20916666666666667\n",
      "Epoch: 8 Training loss: 0.0014663223425547282  | Training Accuracy: 0.25\n",
      "Epoch: 9 Training loss: 0.0014640167355537415  | Training Accuracy: 0.245\n",
      "Epoch: 10 Training loss: 0.0014551534255345662  | Training Accuracy: 0.2708333333333333\n",
      "Epoch: 11 Training loss: 0.0014517199993133545  | Training Accuracy: 0.2825\n",
      "Epoch: 12 Training loss: 0.0014464247226715088  | Training Accuracy: 0.27166666666666667\n",
      "Epoch: 13 Training loss: 0.0014405519763628642  | Training Accuracy: 0.2891666666666667\n",
      "Epoch: 14 Training loss: 0.0014335998892784118  | Training Accuracy: 0.3\n",
      "Epoch: 15 Training loss: 0.0014302915334701539  | Training Accuracy: 0.29083333333333333\n",
      "Epoch: 16 Training loss: 0.001421805719534556  | Training Accuracy: 0.3125\n",
      "Epoch: 17 Training loss: 0.0014155394832293194  | Training Accuracy: 0.335\n",
      "Epoch: 18 Training loss: 0.0014119399587313333  | Training Accuracy: 0.3425\n",
      "Epoch: 19 Training loss: 0.0014044691125551859  | Training Accuracy: 0.35083333333333333\n"
     ]
    }
   ],
   "source": [
    "# Concatenate \n",
    "X = torch.cat((shared_x1, shared_x2), dim=0)\n",
    "Y = torch.cat((shared_y1, shared_y2), dim=0)\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TODO: Define your network architecture here\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(18420, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Create the network, define the criterion and optimizer\n",
    "model = Classifier()\n",
    "# criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    \n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred = model(X)\n",
    "    loss = F.cross_entropy(pred, Y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # statistics\n",
    "    #prob = F.softmax(pred, dim=1)\n",
    "    top1 = torch.argmax(pred, dim=1)\n",
    "    ncorrect = torch.sum(top1 == Y)\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_acc += ncorrect.item()\n",
    "\n",
    "    epoch_loss /= Y.shape[0]\n",
    "    epoch_acc /= Y.shape[0]\n",
    "\n",
    "    print(f\"Epoch: {e}\",f\"Training loss: {epoch_loss}\", f\" | Training Accuracy: {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 - Tagging tensors</h2>\n",
    "The code below will add a tag (of your choice) to the data that will be sent to grid nodes. This tag is important as the network will need it to retrieve this data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_input = []\n",
    "tag_label = []\n",
    "\n",
    "for i in range(len(compute_nodes)):\n",
    "    tag_input.append(datasets[i].tag(\"#X\", \"#gtex_v8\", \"#dataset\",\"#balanced\").describe(\"The input datapoints to the GTEx_V8 dataset.\"))\n",
    "    tag_label.append(labels[i].tag(\"#Y\", \"#gtex_v8\", \"#dataset\",\"#balanced\").describe(\"The input labels to the GTEx_V8 dataset.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3 - Sending our tensors to grid nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_x1 = tag_input[0].send(compute_nodes[0]) # First chunk of dataset to h1\n",
    "shared_x2 = tag_input[1].send(compute_nodes[1]) # Second chunk of dataset to h2\n",
    "\n",
    "shared_y1 = tag_label[0].send(compute_nodes[0]) # First chunk of labels to h1\n",
    "shared_y2 = tag_label[1].send(compute_nodes[1]) # Second chunk of labels to h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor pointers:  (Wrapper)>[PointerTensor | me:23284623177 -> h1:84769424305]\n",
      "\tTags: #gtex_v8 #dataset #balanced #X \n",
      "\tShape: torch.Size([600, 18420])\n",
      "\tDescription: The input datapoints to the GTEx_V8 dataset.... (Wrapper)>[PointerTensor | me:19362357387 -> h2:87452156177]\n",
      "\tTags: #gtex_v8 #dataset #balanced #X \n",
      "\tShape: torch.Size([600, 18420])\n",
      "\tDescription: The input datapoints to the GTEx_V8 dataset....\n",
      "Y tensor pointers:  (Wrapper)>[PointerTensor | me:21210979203 -> h1:4194035554]\n",
      "\tTags: #gtex_v8 #dataset #balanced #Y \n",
      "\tShape: torch.Size([600])\n",
      "\tDescription: The input labels to the GTEx_V8 dataset.... (Wrapper)>[PointerTensor | me:14991428073 -> h2:94399344004]\n",
      "\tTags: #gtex_v8 #dataset #balanced #Y \n",
      "\tShape: torch.Size([600])\n",
      "\tDescription: The input labels to the GTEx_V8 dataset....\n"
     ]
    }
   ],
   "source": [
    "print(\"X tensor pointers: \", shared_x1, shared_x2)\n",
    "print(\"Y tensor pointers: \", shared_y1, shared_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Disconnect nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(compute_nodes)):\n",
    "    compute_nodes[i].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysyft_v028]",
   "language": "python",
   "name": "conda-env-pysyft_v028-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
