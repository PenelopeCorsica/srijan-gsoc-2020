{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Federated Learning - GTEx_V8 Example</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies for helper functions/classes\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from typing import NamedTuple\n",
    "import os.path as path\n",
    "import os\n",
    "import progressbar\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "#keras for ML\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.utils import plot_model, normalize\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam, Adadelta\n",
    "from tensorflow.keras.activations import relu, elu, sigmoid\n",
    "\n",
    "#sklearn for preprocessing the data and train-test split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#for plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Parameter cell -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "_test_size = 0.3\n",
    "comms_round = 2\n",
    "local_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Labels(NamedTuple):\n",
    "    '''\n",
    "    One-hot labeled data\n",
    "    '''\n",
    "    tissue: np.ndarray\n",
    "    sex: np.ndarray\n",
    "    age: np.ndarray\n",
    "    death: np.ndarray\n",
    "        \n",
    "\n",
    "class Genes:\n",
    "    '''\n",
    "    Class to load GTEX samples and gene expressions data\n",
    "    '''\n",
    "    def __init__(self, samples_path: str = '', expressions_path: str = '', problem_type: str = \"classification\"):\n",
    "        self.__set_samples(samples_path)\n",
    "        self.__set_labels(problem_type)\n",
    "        if expressions_path != '':\n",
    "            self.expressions = self.get_expressions(expressions_path)\n",
    "\n",
    "    def __set_samples(self, sample_path: str) -> pd.DataFrame:\n",
    "        self.samples: pd.DataFrame = pq.read_table(sample_path).to_pandas()\n",
    "        self.samples[\"Death\"].fillna(-1.0, inplace = True)\n",
    "        self.samples: pd.DataFrame = self.samples.set_index(\"Name\")\n",
    "        self.samples[\"Sex\"].replace([1, 2], ['male', 'female'], inplace=True)\n",
    "        self.samples[\"Death\"].replace([-1,0,1,2,3,4], ['alive/NA', 'ventilator case', '<10 min.', '<1 hr', '1-24 hr.', '>1 day'], inplace=True)\n",
    "        self.samples = self.samples[~self.samples['Death'].isin(['>1 day'])]\n",
    "        return self.samples\n",
    "\n",
    "    def __set_labels(self, problem_type: str = \"classification\") -> Labels:\n",
    "        self.labels_list = [\"Tissue\", \"Sex\", \"Age\", \"Death\"]\n",
    "        self.labels: pd.DataFrame = self.samples[self.labels_list]\n",
    "        self.drop_list = self.labels_list + [\"Subtissue\", \"Avg_age\"]\n",
    "        \n",
    "        if problem_type == \"classification\":\n",
    "            dummies_df = pd.get_dummies(self.labels[\"Age\"])\n",
    "            print(dummies_df.columns.tolist())\n",
    "            self.Y = dummies_df.values\n",
    "        \n",
    "        if problem_type == \"regression\":\n",
    "            self.Y = self.samples[\"Avg_age\"].values\n",
    "        \n",
    "        return self.Y\n",
    "\n",
    "    def sex_output(self, model):\n",
    "        return Dense(units=self.Y.sex.shape[1], activation='softmax', name='sex_output')(model)\n",
    "\n",
    "    def tissue_output(self, model):\n",
    "        return Dense(units=self.Y.tissue.shape[1], activation='softmax', name='tissue_output')(model)\n",
    "\n",
    "    def death_output(self, model):\n",
    "        return Dense(units=self.Y.death.shape[1], activation='softmax', name='death_output')(model)\n",
    "\n",
    "    def age_output(self, model):\n",
    "        '''\n",
    "        Created an output layer for the keras mode\n",
    "        :param model: keras model\n",
    "        :return: keras Dense layer\n",
    "        '''\n",
    "        return Dense(units=self.Y.age.shape[1], activation='softmax', name='age_output')(model)\n",
    "\n",
    "\n",
    "    def get_expressions(self, expressions_path: str)->pd.DataFrame:\n",
    "        '''\n",
    "        load gene expressions DataFrame\n",
    "        :param expressions_path: path to file with expressions\n",
    "        :return: pandas dataframe with expression\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        if expressions_path.endswith(\".parquet\"):\n",
    "            return pq.read_table(expressions_path).to_pandas().set_index(\"Name\") \n",
    "        else:\n",
    "            separator = \",\" if expressions_path.endswith(\".csv\") else \"\\t\"\n",
    "            return pd.read_csv(expressions_path, sep=separator).set_index(\"Name\") \n",
    "\n",
    "    def prepare_data(self, normalize_expressions: bool = True)-> np.ndarray:\n",
    "        '''\n",
    "        :param normalize_expressions: if keras should normalize gene expressions\n",
    "        :return: X array to be used as input data by keras\n",
    "        '''\n",
    "        data = self.samples.join(self.expressions, on = \"Name\", how=\"inner\")\n",
    "        ji = data.columns.drop(self.drop_list)\n",
    "        x = data[ji]\n",
    "        \n",
    "        # adding one-hot-encoded tissues and sex\n",
    "        #x = pd.concat([x,pd.get_dummies(data['Tissue'], prefix='tissue'), pd.get_dummies(data['Sex'], prefix='sex')],axis=1)\n",
    "        \n",
    "        steps = [('standardization', StandardScaler()), ('normalization', MinMaxScaler())]\n",
    "        pre_processing_pipeline = Pipeline(steps)\n",
    "        transformed_data = pre_processing_pipeline.fit_transform(x)\n",
    "\n",
    "        x = transformed_data\n",
    "        \n",
    "        print('Data length', len(x))\n",
    "        \n",
    "        return x #normalize(x, axis=0) if normalize_expressions else x\n",
    "    \n",
    "    def get_features_dataframe(self, add_tissues=False):\n",
    "        data = self.samples.join(self.expressions, on = \"Name\", how=\"inner\")\n",
    "        ji = data.columns.drop(self.drop_list)\n",
    "        df = data[ji]\n",
    "        if add_tissues:\n",
    "            df = pd.concat([df,pd.get_dummies(data['Tissue'], prefix='tissue'), pd.get_dummies(data['Sex'], prefix='sex')],axis=1)\n",
    "        x = df.values\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df_normalized = pd.DataFrame(x_scaled, columns=df.columns, index=df.index)\n",
    "        return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = '../data/gtex/v8_samples.parquet'\n",
    "expressions_path = '../data/gtex/v8_expressions.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length 15343\n"
     ]
    }
   ],
   "source": [
    "genes = Genes(samples_path, expressions_path, problem_type=\"regression\")\n",
    "X = genes.prepare_data(True)\n",
    "Y = genes.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=_test_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=2, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['client_1', 'client_2']), (18388,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.keys(), clients['client_1'][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data_shard, bs=256):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['client_1', 'client_2']),\n",
       " <BatchDataset shapes: ((None, 18388), (None,)), types: (tf.float32, tf.float64)>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_batched.keys(),clients_batched['client_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def optimized_age_model_regression():\n",
    "    # optimized_age_model(x_train, x_val, y_train, y_val, params: dict):\n",
    "    input_layer = Input(shape=(clients['client_1'][0][0].shape[0],))\n",
    "    reg = keras.regularizers.l1_l2(l1=0.3, l2=0.3)\n",
    "    mod = Dense(1024, activation=relu)(input_layer) # 196\n",
    "    mod = Dropout(0.1)(mod) \n",
    "    mod = Dense(512, activation=relu)(mod) # 196\n",
    "    mod = Dropout(0.1)(mod)    \n",
    "    mod = Dense(64, activation=relu)(mod) #64\n",
    "    mod = Dropout(0.1)(mod)\n",
    "    \n",
    "    outputs = [Dense(1, name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    #outputs = [Dense(y_train.shape[1], activation='sigmoid', name='age_output')(mod)] #let's try to make it simple and start with age \n",
    "    loss = {'age_output': 'mse'}\n",
    "    weights={'age_output': 1.0}\n",
    "    metrics = {'age_output': ['mae', coeff_determination]}\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              loss_weights=weights,\n",
    "              metrics=metrics,\n",
    "                 )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Huber(yHat, y, delta=1.):\n",
    "    return np.where(np.abs(y-yHat) < delta,.5*(y-yHat)**2 , delta*(np.abs(y-yHat)-0.5*delta))\n",
    "\n",
    "def transform_to_probas(age_intervals):\n",
    "    class_names = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "    res = []\n",
    "    for a in age_intervals:\n",
    "        non_zero_index = class_names.index(a)\n",
    "        res.append([0 if i != non_zero_index else 1 for i in range(len(class_names))])\n",
    "    return np.array(res)\n",
    "    \n",
    "def transform_to_interval(age_probas):\n",
    "    class_names = ['20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "    return np.array(list(map(lambda p: class_names[np.argmax(p)], age_probas)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "client_1 | Round:  0\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 14s 662ms/step - loss: 751.2528 - mae: 21.9372 - coeff_determination: -3.7259\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 12s 568ms/step - loss: 345.0550 - mae: 14.7175 - coeff_determination: -1.1899\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 12s 588ms/step - loss: 285.3497 - mae: 13.4197 - coeff_determination: -0.8015\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 12s 583ms/step - loss: 246.9043 - mae: 12.5560 - coeff_determination: -0.5776\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 13s 620ms/step - loss: 224.5098 - mae: 12.0295 - coeff_determination: -0.4279\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 11s 536ms/step - loss: 209.8430 - mae: 11.6880 - coeff_determination: -0.3325\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 13s 630ms/step - loss: 181.2900 - mae: 10.7848 - coeff_determination: -0.1587\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 14s 672ms/step - loss: 173.3690 - mae: 10.6032 - coeff_determination: -0.0992\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 13s 638ms/step - loss: 157.7259 - mae: 10.1215 - coeff_determination: 0.0023\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 12s 578ms/step - loss: 142.6546 - mae: 9.6821 - coeff_determination: 0.0870\n",
      "client_2 | Round:  0\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 14s 667ms/step - loss: 735.9165 - mae: 21.6754 - coeff_determination: -3.5359\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 16s 758ms/step - loss: 356.1265 - mae: 15.0070 - coeff_determination: -1.1578\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 15s 694ms/step - loss: 285.8122 - mae: 13.3993 - coeff_determination: -0.7367\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 13s 630ms/step - loss: 258.8863 - mae: 12.8040 - coeff_determination: -0.5621\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 12s 591ms/step - loss: 231.4741 - mae: 12.0974 - coeff_determination: -0.3976\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 13s 633ms/step - loss: 206.4371 - mae: 11.6188 - coeff_determination: -0.2620\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 13s 625ms/step - loss: 193.7802 - mae: 11.2157 - coeff_determination: -0.1739\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 13s 619ms/step - loss: 173.6432 - mae: 10.6798 - coeff_determination: -0.0558\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 13s 599ms/step - loss: 167.1289 - mae: 10.5190 - coeff_determination: -0.0366\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 12s 569ms/step - loss: 155.4039 - mae: 10.0329 - coeff_determination: 0.0578\n",
      "R^2 -1.2431583113572904\n",
      "Mean squared error 374.08063300555426\n",
      "Mean absolute error 17.138829686448492\n",
      "Huber loss 17.634580859827484\n",
      "client_1 | Round:  1\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 14s 671ms/step - loss: 457.4826 - mae: 17.1481 - coeff_determination: -1.9999\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 12s 579ms/step - loss: 205.5565 - mae: 11.5510 - coeff_determination: -0.3043\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 12s 589ms/step - loss: 170.6228 - mae: 10.4677 - coeff_determination: -0.0770\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 12s 570ms/step - loss: 155.6456 - mae: 10.0876 - coeff_determination: 0.0062\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 13s 596ms/step - loss: 146.6282 - mae: 9.7449 - coeff_determination: 0.0655\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 13s 618ms/step - loss: 143.1265 - mae: 9.5789 - coeff_determination: 0.0926\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 13s 599ms/step - loss: 134.0767 - mae: 9.2698 - coeff_determination: 0.1450\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 12s 586ms/step - loss: 128.4063 - mae: 9.1534 - coeff_determination: 0.1714\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 12s 591ms/step - loss: 137.7471 - mae: 9.4360 - coeff_determination: 0.1233\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 12s 591ms/step - loss: 125.9597 - mae: 9.0501 - coeff_determination: 0.1961\n",
      "client_2 | Round:  1\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18388)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              18830336  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "age_output (Dense)           (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,388,033\n",
      "Trainable params: 19,388,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 13s 627ms/step - loss: 488.1224 - mae: 17.7551 - coeff_determination: -1.9523\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 15s 695ms/step - loss: 213.7240 - mae: 11.7681 - coeff_determination: -0.2794\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 12s 560ms/step - loss: 172.0350 - mae: 10.6067 - coeff_determination: -0.0425\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 12s 560ms/step - loss: 164.9320 - mae: 10.3644 - coeff_determination: 0.0029\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 12s 579ms/step - loss: 150.8412 - mae: 9.9671 - coeff_determination: 0.0805\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 12s 568ms/step - loss: 145.6674 - mae: 9.7303 - coeff_determination: 0.1170\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 12s 565ms/step - loss: 138.3983 - mae: 9.5099 - coeff_determination: 0.1597\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 12s 570ms/step - loss: 132.7624 - mae: 9.2774 - coeff_determination: 0.1979\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 12s 578ms/step - loss: 131.3841 - mae: 9.2505 - coeff_determination: 0.2004\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 12s 572ms/step - loss: 130.6783 - mae: 9.1459 - coeff_determination: 0.2138\n",
      "R^2 -0.06301750491201186\n",
      "Mean squared error 177.27427400915704\n",
      "Mean absolute error 11.382869909412053\n",
      "Huber loss 13.159827672277185\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "mae = []\n",
    "r2 = []\n",
    "huber_loss = []\n",
    "    \n",
    "global_model = optimized_age_model_regression()\n",
    "    \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "    \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        print(client, '| Round: ', comm_round)\n",
    "\n",
    "        \n",
    "        local_model = optimized_age_model_regression()\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        \n",
    "        local_model.fit(clients_batched[client], epochs=local_epochs, verbose=1)\n",
    "#         predictions = local_model.predict(X_test)\n",
    "#         test_y = y_test\n",
    "\n",
    "#         print(\"R^2\", r2_score(test_y, predictions))\n",
    "#         print(\"Mean squared error\", mean_squared_error(test_y, predictions))\n",
    "#         print(\"Mean absolute error\", mean_absolute_error(test_y, predictions))\n",
    "#         print('Huber loss', np.mean(Huber(test_y, predictions)))\n",
    "\n",
    "        rmse.append(mean_squared_error(test_y, predictions))\n",
    "        mae.append(mean_absolute_error(test_y, predictions))\n",
    "        r2.append(r2_score(test_y, predictions))\n",
    "        huber_loss.append(np.mean(Huber(test_y, predictions)))\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "    \n",
    "    predictions = global_model.predict(X_test)\n",
    "    test_y = y_test\n",
    "\n",
    "    print(\"R^2\", r2_score(test_y, predictions))\n",
    "    print(\"Mean squared error\", mean_squared_error(test_y, predictions))\n",
    "    print(\"Mean absolute error\", mean_absolute_error(test_y, predictions))\n",
    "    print('Huber loss', np.mean(Huber(test_y, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pysyft_v028] *",
   "language": "python",
   "name": "conda-env-pysyft_v028-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
